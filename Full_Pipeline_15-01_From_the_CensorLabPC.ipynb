{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some standard pythonic imports\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "import os,numpy as np,pandas as pd\n",
    "from collections import OrderedDict\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "# MNE functions\n",
    "import mne\n",
    "from mne import Epochs,find_events\n",
    "from mne.decoding import Vectorizer\n",
    "\n",
    "#MNE XDF Importer\n",
    "from mne_import_xdf import *\n",
    "\n",
    "# Scikit-learn and Pyriemann ML functionalities\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.svm import SVC  # Support Vector Classifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import ShuffleSplit, cross_val_score,train_test_split\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, StratifiedShuffleSplit, train_test_split\n",
    "from pyriemann.estimation import ERPCovariances, XdawnCovariances, Xdawn, Covariances\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from pyriemann.classification import MDM\n",
    "import mne\n",
    "\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "from mne.datasets import eegbci\n",
    "from mne.decoding import CSP\n",
    "\n",
    "\n",
    "\n",
    "import pyxdf\n",
    "import PyQt5\n",
    "\n",
    "from easygui import *\n",
    "\n",
    "import pathlib\n",
    "\n",
    "# For interactive plots\n",
    "from IPython import get_ipython\n",
    "get_ipython().run_line_magic('matplotlib', 'qt')\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import json\n",
    "\n",
    "#import moab to get the filterbank implementation: \n",
    "from moabb.pipelines.utils import FilterBank\n",
    "\n",
    "#imports for precision_recall_curve related plot: \n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve,PrecisionRecallDisplay\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from itertools import cycle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the output folder does not exists:   c:\\Users\\gilad\\3_Class_MI\\3_Class_MI\\figures_outputs\n",
      "all available recording files ['Gilad_ses-1_task-mi_run-001_eeg.xdf', 'Gilad_ses-1_task-mi_run-002_eeg.xdf', 'Gilad_ses-1_task-mi_run-003_eeg.xdf', 'Gilad_ses-1_task-mi_run-004_eeg.xdf', 'G_BCI_No_AO.xdf', 'Neta_AO_1Hand.xdf', 'Neta_AO_2Hands.xdf', 'Neta_NoAO_1Hand.xdf', 'Neta_NoAO_2Hands.xdf', 'NH_Block_1.xdf', 'NH_Block_2.xdf', 'NH_Block_3.xdf', 'OldGilad_AO.xdf', 'Ro555ei_P300.xdf', 'Ro555ei_P300_1_24_05.xdf', 'Ron-Block_1.xdf', 'Ron-Block_2.xdf', 'Ron-Block_3.xdf', 'Ron-Block_4.xdf', 'sub-Roei_ses-MI1_task-Default_run-001_eeg.xdf', 'sub-Roei_ses-MI2_task-Default_run-001_eeg.xdf', 'sub-Roei_ses-Mi3_task-Default_run-001_eeg.xdf']\n",
      "only subjects IDS: ['Gilad', 'Gilad', 'Gilad', 'Gilad', 'G', 'Neta', 'Neta', 'Neta', 'Neta', 'NH', 'NH', 'NH', 'OldGilad', 'Ro555ei', 'Ro555ei', 'Ron-Block', 'Ron-Block', 'Ron-Block', 'Ron-Block', 'sub-Roei', 'sub-Roei', 'sub-Roei']\n"
     ]
    }
   ],
   "source": [
    "#define paths: \n",
    "current_path = pathlib.Path().absolute()  \n",
    "recording_path = current_path / 'Recordings'\n",
    "figure_outputs_path=current_path / 'figures_outputs'\n",
    "hyper_param_search_output=current_path / 'hyper_param_search_outputs'\n",
    "#extract all recorded files and subject names\n",
    "recording_files = [f for f in listdir(recording_path) if isfile(join(recording_path, f)) and ('.xdf' in f)]\n",
    "if not(figure_outputs_path.exists()):\n",
    "    print('the output folder does not exists:  ',figure_outputs_path)\n",
    "\n",
    "if not(hyper_param_search_output.exists()):\n",
    "    print('the output folder does not exists:  ',hyper_param_search_output)\n",
    "\n",
    "\n",
    "print('all available recording files',recording_files)\n",
    "subject_names=[r.split('_')[0] for r in recording_files]\n",
    "print('only subjects IDS:',subject_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filenames:\n",
      " ['Gilad_ses-1_task-mi_run-001_eeg.xdf', 'Gilad_ses-1_task-mi_run-002_eeg.xdf', 'Gilad_ses-1_task-mi_run-003_eeg.xdf', 'Gilad_ses-1_task-mi_run-004_eeg.xdf', 'G_BCI_No_AO.xdf', 'Neta_AO_1Hand.xdf', 'Neta_AO_2Hands.xdf', 'Neta_NoAO_1Hand.xdf', 'Neta_NoAO_2Hands.xdf', 'NH_Block_1.xdf', 'NH_Block_2.xdf', 'NH_Block_3.xdf', 'OldGilad_AO.xdf', 'Ro555ei_P300.xdf', 'Ro555ei_P300_1_24_05.xdf', 'Ron-Block_1.xdf', 'Ron-Block_2.xdf', 'Ron-Block_3.xdf', 'Ron-Block_4.xdf', 'sub-Roei_ses-MI1_task-Default_run-001_eeg.xdf', 'sub-Roei_ses-MI2_task-Default_run-001_eeg.xdf', 'sub-Roei_ses-Mi3_task-Default_run-001_eeg.xdf']\n",
      "names:\n",
      " ['Gilad', 'Gilad', 'Gilad', 'Gilad', 'G', 'Neta', 'Neta', 'Neta', 'Neta', 'NH', 'NH', 'NH', 'OldGilad', 'Ro555ei', 'Ro555ei', 'Ron-Block', 'Ron-Block', 'Ron-Block', 'Ron-Block', 'sub-Roei', 'sub-Roei', 'sub-Roei']\n",
      "grid options [[0], [0, 1], [0, 1, 2], [0], [0, 1], [0], [0, 1], [0], [0], [0, 1], [0, 1], [0, 1, 2]]\n",
      "number of grid search iterations: 288\n",
      "Grid info: {'filter_methods': ['iir'], 'run_csd': [True, False], 'pipeline_name': ['csp+lda', 'ts+lda', 'fbcsp+lda'], 'bandpass_borders_grid': [[7, 32]], 'Electorde_Groups_names_grid': ['C', 'PO'], 'n_components_grid': [4], 'n_components_fbcsp_grid': [2, 3], 'filters_bands': [[8, 12]], 'epoch_tmins_and_maxes_grid': [[-3, 4]], 'classifier_training_windows_grid': [[1, 2], [1, 3]], 'augmentation_windows_grid': [[0, 0], [0.5, 0.5]], 'windowed_prediction_params': [[0.5, 0.1], [0.75, 0.1], [1, 0.1]]}\n"
     ]
    }
   ],
   "source": [
    "#initial defitions: \n",
    "print('filenames:\\n',recording_files)\n",
    "print('names:\\n',subject_names)\n",
    "\n",
    "Use_test_grid=False #change to False when you want to use the real grid_search and not a toy one: \n",
    "\n",
    "#define the electdode groups: the key can be anything, the values should be a list of electrodes\n",
    "Electorde_Groups = {'FP': ['Fp1', 'Fp2'],\n",
    "                   'AF': ['AF7', 'AF3', 'AFz', 'AF4', 'AF8'],\n",
    "                   'F' : ['F7', 'F5', 'F3', 'F1', 'Fz', 'F2', 'F4', 'F6', 'F8'],\n",
    "                   'FC': ['FC5', 'FC3', 'FC1', 'FC2', 'FC4', 'FC6', 'FT7','FT8'],\n",
    "                   'C' : ['C5', 'C3', 'C1', 'Cz', 'C2', 'C4' ,'C6'],\n",
    "                   'CP': ['CP5', 'CP3', 'CP1','CPz', 'CP2', 'CP4', 'CP6'],\n",
    "                   'P' : ['P7', 'P5','P3', 'P1', 'Pz', 'P2', 'P4', 'P6', 'P8'],\n",
    "                   'PO': ['PO7', 'PO3', 'POz', 'PO4', 'PO8'],\n",
    "                   'O' : ['Oz', 'O2', 'O1', 'Iz']\n",
    "                  } \n",
    "\n",
    "#define the grid search (dont go all at once because some params are not relevant to other params and might just increase running time: \n",
    "# i.e if using fbcsp, the n_components_grid paramater is not used, so if it has more than 1 value, it will run the fbcsp twice while changing a paramter that does not effect the calculation)\n",
    "grid_search_dict=OrderedDict()\n",
    "grid_search_dict={'filter_methods':['iir'], #['irr' or 'fir']\n",
    "                'run_csd':[True, False],\n",
    "                'pipeline_name':['csp+lda','ts+lda','fbcsp+lda'], #these classifiers pipelines are defined in \"run_windowed_classification_on_fold\"\n",
    "                #things to do: filter bank csp + lda, csp+ts+lda\n",
    "                'bandpass_borders_grid':[[7,32]], #each list defines the low and high cutoffs\n",
    "                'Electorde_Groups_names_grid':['C','PO'], #each \"name\" refers to an elec group defined above\n",
    "                'n_components_grid':[4], #the n component options for the csp classifier\n",
    "                'n_components_fbcsp_grid':[2,3], # the n components options to use in the fbcsp classifier (n * filter_bank_bands)\\\n",
    "                'filters_bands':[[8,12]],#[[[8, 12], [12, 20], [20, 32]]],\n",
    "                'epoch_tmins_and_maxes_grid':[[-3,4]], #times (sec: pre,post) for initial epoching (this should be the longest epoch as the windowed prediction will be tested on it)\n",
    "                'classifier_training_windows_grid':[[1 , 2],[1,3]], #what times(sec: start,end) to use for the classifer training (data augmentation is also using this window)\n",
    "                'augmentation_windows_grid':[[0,0],[0.5,0.5]], #referes to proportions (win_len,win_step) of sfreq, [1,1] means taking the classification epochs, and creating 1 second long epochs with 1 second long steps\n",
    "                'windowed_prediction_params':[[0.5,0.1],[0.75,0.1],[1,0.1]]} #refers to prportions (win_len,win_step) of sfreq to try and predict i.e. 0.5 = half a second window, with a 100ms steps  \n",
    "\n",
    "#here you can define a test grid (make it small so it wont take long, and use it to check that everything is working) \n",
    "test_grid_search_dict={'filter_methods':['fir'], #['irr' or 'fir']\n",
    "                'run_csd':[True],\n",
    "                'pipeline_name':['csp+lda'], #these classifiers pipelines are defined in \"run_windowed_classification_on_fold\n",
    "                #things to do: filter bank csp + lda, csp+ts+lda\n",
    "                'bandpass_borders_grid':[[8,32]], #each list defines the low and high cutoffs\n",
    "                'Electorde_Groups_names_grid':['C','PO'], #each \"name\" refers to an elec group defined above\n",
    "                'n_components_grid':[4], #the n component options for the csp classifier\n",
    "                'n_components_fbcsp_grid':[3], # the n components options to use in the fbcsp classifier (n * filter_bank_bands)\n",
    "                'filters_bands':[[[8, 12], [12, 20], [20, 32]]],\n",
    "                'epoch_tmins_and_maxes_grid':[[-3,5]], #times (sec: pre,post) for initial epoching (this should be the longest epoch as the windowed prediction will be tested on it)\n",
    "                'classifier_training_windows_grid':[[0,2]], #what times(sec: start,end) to use for the classifer training (data augmentation is also using this window)\n",
    "                'augmentation_windows_grid':[[1,0.1]], #referes to proportions (win_len,win_step) of sfreq, [1,1] means taking the classification epochs, and creating 1 second long epochs with 1 second long steps\n",
    "                'windowed_prediction_params':[[1,0.1]]} #refers to prportions (win_len,win_step) of sfreq to try and predict i.e. 0.5 = half a second window, with a 100ms steps  \n",
    "\n",
    "if Use_test_grid: \n",
    "   print('\\n######\\nusing a test grid search\\n######\\n')\n",
    "   grid_search_dict=test_grid_search_dict\n",
    "\n",
    "all_options=[list(range(len(val))) for key,val in grid_search_dict.items()]\n",
    "print(f'grid options {all_options}')\n",
    "#get all possible grid_search combinations: \n",
    "all_grid_combinations = list(itertools.product(*all_options))\n",
    "print(f'number of grid search iterations: {len(all_grid_combinations)}')\n",
    "print('Grid info:',grid_search_dict)\n",
    "#save the hyper_grid_search: \n",
    "with open(hyper_param_search_output/'grid_search_info.json', 'w') as file:\n",
    "    json.dump(grid_search_dict, file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define trigger and bad electrodes information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the trigger info per participant\n",
    "#new subjects should be added here, untill we decide on a single trigger... \n",
    "def define_events_trigger_values_per_recording_file(recording_file):\n",
    "    events_dictionary={'Dekel_AO.xdf':{3:'left',6:'right'},\n",
    "                    'Dekel_AoNoMI.xdf':{3:'left',6:'right'},\n",
    "                    'Dekel_NoAO.xdf':{3:'left',6:'right'}, \n",
    "                    'Gilad_AO.xdf':{4:'left',7:'right'}, \n",
    "                    'Neta_AO_1Hand.xdf':{2:'close',5:'open'},\n",
    "                    'Neta_AO_2Hands.xdf':{3:'left',6:'right'},\n",
    "                    'Neta_NoAO_1Hand.xdf':{2:'close',5:'open'},\n",
    "                    'Neta_NoAO_2Hands.xdf':{3:'left',6:'right'},\n",
    "                    'Ron-Block_2.xdf':{3:'left',6:'rest',7:'right'},\n",
    "                    'Ron-Block_3.xdf':{3:'left',6:'rest',7:'right'},\n",
    "                    'Ron-Block_4.xdf':{3:'left',6:'rest',7:'right'},\n",
    "                    'sub-Roei_ses-MI1_task-Default_run-001_eeg.xdf': {2:'left',5:'rest',6:'right'}, \n",
    "                    'sub-Roei_ses-MI2_task-Default_run-001_eeg.xdf': {3:'left',6:'rest',7:'right'},  \n",
    "                    'sub-Roei_ses-Mi3_task-Default_run-001_eeg.xdf': {3:'left',6:'rest',7:'right'},\n",
    "                    'NH_Block_1.xdf': {3:'left',6:'rest',7:'right'},\n",
    "                    'NH_Block_2.xdf': {3:'left',6:'rest',7:'right'},\n",
    "                    'NH_Block_3.xdf': {3:'left',6:'rest',7:'right'}}\n",
    "    if recording_file not in events_dictionary.keys():\n",
    "        raise Exception(f'the current recording file {recording_file} does not have a defined triggers in the function \"define_events_triggers_Values_per_recorindg_file')\n",
    "    \n",
    "    trigger_info_dict=events_dictionary[recording_file]\n",
    "    return trigger_info_dict\n",
    "    \n",
    "\n",
    "#define what electdodes should be excluded (based on whatever method you'd like (probably visual inspection of the recordings))\n",
    "def get_subject_bad_electrodes(subject):\n",
    "    elecs_to_drop={}\n",
    "    #define here the subject specific electdodes to make sure are removed from the data: \n",
    "    bad_elecs_dict={'Dekel':{'FT10', 'TP10', 'FT9'},\n",
    "                    'Gilad':{'FT10', 'TP10', 'FT9', 'TP9'},\n",
    "                    'Neta':{'TP9'},\n",
    "                    'Ron-Block':{'PO7'},\n",
    "                    'sub-Roei': {'TP9'},\n",
    "                    'NH' : {'TP7'}}\n",
    "    if subject in bad_elecs_dict.keys():\n",
    "        subject_bad_electrodes=bad_elecs_dict[subject]\n",
    "    else: \n",
    "        subject_bad_electrodes={}\n",
    "        print('note that no bad electrodes were defined for the current subject:',subject)\n",
    "    return subject_bad_electrodes   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_up_params_for_current_grid_iteration(all_grid_combinations,iteration_ind,grid_search_dict):\n",
    "    curr_grid_comb=all_grid_combinations[iteration_ind]\n",
    "    print(f'setting up current params: iteration {iteration_ind} - grid settings: {curr_grid_comb}')\n",
    "    #create a dictionary from the current grid combination (note that the dictionary is ordered): \n",
    "    iteration_dictionary={key:val[inner_ind] for ((key,val),inner_ind) in zip(grid_search_dict.items(),curr_grid_comb)}\n",
    "   \n",
    "    #extract the paramaters for the current iteration: \n",
    "    LowPass=iteration_dictionary['bandpass_borders_grid'][0]\n",
    "    HighPass=iteration_dictionary['bandpass_borders_grid'][1]\n",
    "    PerformCsd=iteration_dictionary['run_csd']\n",
    "    filter_method=iteration_dictionary['filter_methods']\n",
    "\n",
    "    #extract current electrodes (allow for combination of electrode groups i.e 'C+AF+F')\n",
    "    Electorde_Group_name=iteration_dictionary['Electorde_Groups_names_grid'] #['FP', 'AF', 'F', 'FC', 'C', 'CP', 'P', 'PO', 'O']\n",
    "    Electorde_Group=[]\n",
    "    for cur_elec_group_name in Electorde_Group_name.split('+'):\n",
    "        Electorde_Group=Electorde_Group+Electorde_Groups[cur_elec_group_name]\n",
    "    classifier_window_s=iteration_dictionary['classifier_training_windows_grid'][0]\n",
    "    classifier_window_e=iteration_dictionary['classifier_training_windows_grid'][1]\n",
    "    epoch_tmin=iteration_dictionary['epoch_tmins_and_maxes_grid'][0]\n",
    "    epoch_tmax=iteration_dictionary['epoch_tmins_and_maxes_grid'][1]\n",
    "    n_components=iteration_dictionary['n_components_grid']\n",
    "    n_components_fbcsp=iteration_dictionary['n_components_fbcsp_grid']\n",
    "    #define the current augmentation paramaters to test: note that they are defined by samples\n",
    "    augmentation_params={'win_len':iteration_dictionary['augmentation_windows_grid'][0],\n",
    "                        'win_step':iteration_dictionary['augmentation_windows_grid'][1]}\n",
    "    #define the windowed prediction paramaters: #here they are defined as proportions of the sampling frequency\n",
    "    windowed_prediction_params={'win_len':iteration_dictionary['windowed_prediction_params'][0],\n",
    "                                'win_step':iteration_dictionary['windowed_prediction_params'][1]}\n",
    "    #get the current pipeline name: \n",
    "    pipeline_name=iteration_dictionary['pipeline_name']\n",
    "    filters_bands=iteration_dictionary['filters_bands']                          \n",
    "    #set paramaters dict for current run: \n",
    "    params_dict={'LowPass': LowPass,\n",
    "                'HighPass': HighPass,\n",
    "                'PerformCsd':PerformCsd,\n",
    "                'filter_method':filter_method,\n",
    "                'n_components':n_components,\n",
    "                'n_components_fbcsp':n_components_fbcsp,\n",
    "                'filters_bands':filters_bands,\n",
    "                'Electorde_Group':Electorde_Group,\n",
    "                'Electorde_Group_name':Electorde_Group_name,\n",
    "                'epoch_tmin':epoch_tmin,\n",
    "                'epoch_tmax':epoch_tmax,\n",
    "                'classifier_window_s':classifier_window_s,\n",
    "                'classifier_window_e':classifier_window_e,\n",
    "                'augmentation_params':augmentation_params,\n",
    "                'windowed_prediction_params':windowed_prediction_params,\n",
    "                'pipeline_name':pipeline_name}\n",
    "\n",
    "    return params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to define a preprocessing function that can accept several participant files and add them to a single structure. \n",
    "def run_pre_processing_extract_validation_set(recording_path,current_path,params_dict):\n",
    "\n",
    "    #extract the current run paramaters: \n",
    "    Subject=params_dict['subject']\n",
    "    PerformCsd=params_dict['PerformCsd']\n",
    "    LowPass, HighPass, filter_method = params_dict['LowPass'],params_dict['HighPass'],params_dict['filter_method']\n",
    "    tmin=params_dict['epoch_tmin']\n",
    "    tmax=params_dict['epoch_tmax']\n",
    "\n",
    "    #events_trigger_dict=define_events_trigger_values_per_recording_file(params_dict['recording_file']) # could be redundant after changes to event_dict\n",
    "    #events_trigger_dict={val:key for key,val in events_trigger_dict.items()}\n",
    "\n",
    "    #read the file:\n",
    "    Raw=read_raw_xdf(recording_path / params_dict['recording_file'])\n",
    "    #remove non existent channels: \n",
    "    Raw.drop_channels(['ACC_X','ACC_Y','ACC_Z']) ## Drop non eeg channels\n",
    "    #set the correct (Brainvision Montage) montage:\n",
    "    montage = mne.channels.read_custom_montage((f\"{current_path}\\Montages\\CACS-64_REF.bvef\"), head_size=0.095, coord_frame=None) \n",
    "    #rename channels for consistency: \n",
    "    mne.rename_channels(Raw.info, {'F9' : 'FT9','P9' : 'TP9','P10' : 'TP10','F10' : 'FT10','AF1' : 'AF7' }, allow_duplicates=False, verbose=None)\n",
    "    Raw.set_montage(montage, match_case=True, match_alias=False, on_missing='raise', verbose=None)\n",
    "\n",
    "    print('\\n###########################################################')\n",
    "    print('removing subject sepecific bad electrodes from the raw data')\n",
    "    #drop bad electrodes according to the current subject name: \n",
    "    print('\\n###########################################################')\n",
    "    print('removing bad channels from epochs:')\n",
    "    curr_elecs_in_epochs_set=set(Raw.info['ch_names'])\n",
    "    elecs_to_remove=get_subject_bad_electrodes(Subject)\n",
    "    elecs_to_drop=curr_elecs_in_epochs_set.intersection(elecs_to_remove)\n",
    "\n",
    "    if len(elecs_to_drop)>0: \n",
    "        Raw.drop_channels(list(elecs_to_drop))\n",
    "    Raw.drop_channels(Raw.info['bads'])\n",
    "\n",
    "    #do csd: \n",
    "    if (PerformCsd):\n",
    "        print('\\n###########################################################')\n",
    "        print('running csd')\n",
    "        Raw_CSD = mne.preprocessing.compute_current_source_density(Raw) ## Compute CSD\n",
    "    else :\n",
    "        print('\\n###########################################################')\n",
    "        print('not using csd')\n",
    "        Raw_CSD = Raw\n",
    "\n",
    "    print('\\n###########################################################')\n",
    "    print('filtering the data')  \n",
    "    unfiltered_Raw_CSD=Raw_CSD.copy()\n",
    "    Raw_CSD_Filtered = unfiltered_Raw_CSD.filter(LowPass, HighPass, method=filter_method)\n",
    "\n",
    "    #extract filterbank feequencies:\n",
    "    filters_bands=tuple(params_dict['filters_bands'])\n",
    "    filtered_data_band_passed=[]\n",
    "    for i,(LowPass,HighPass) in enumerate(filters_bands):\n",
    "        unfiltered_Raw_CSD=Raw_CSD.copy()\n",
    "        Raw_CSD_Filtered_band= unfiltered_Raw_CSD.filter(LowPass, HighPass, method=filter_method)\n",
    "        filtered_data_band_passed.append(Raw_CSD_Filtered_band)\n",
    "\n",
    "    events_from_annot,event_dict = mne.events_from_annotations(Raw_CSD_Filtered)\n",
    "    print('\\n###########################################################')\n",
    "    print('extracting event info:',event_dict)\n",
    "    # Select relevant events for epoching\n",
    "    desired_events = ['Left', 'Right'] \n",
    "    events_trigger_dict = {key: event_dict[key] for key in event_dict.keys() if key in desired_events}\n",
    "    print('\\n###########################################################')\n",
    "    selected_elecs=params_dict['Electorde_Group']\n",
    "\n",
    "    #filter bank related: \n",
    "    filter_bank_epochs=[]\n",
    "    for filtered_data_band in filtered_data_band_passed:\n",
    "        epochs = mne.Epochs(filtered_data_band, events_from_annot,picks=params_dict['Electorde_Group'], preload = True,baseline= None, tmin=tmin, tmax=tmax, event_id=events_trigger_dict,detrend=0)\n",
    "        filter_bank_epochs.append(epochs)\n",
    "\n",
    "    print(f'epoching + selecting current electodes set for analysis:\\n{selected_elecs}')\n",
    "    epochs = mne.Epochs(Raw_CSD_Filtered, events_from_annot,picks=params_dict['Electorde_Group'], preload = True,baseline= None, tmin=tmin, tmax=tmax, event_id=events_trigger_dict,detrend=0)\n",
    "\n",
    "\n",
    "    #this section drops electrodes after epoching: but currently we drop all bad electrodes from the raw data\n",
    "    print('\\n###########################################################')\n",
    "    print('removing bad channels from epochs:')\n",
    "    curr_elecs_in_epochs_set=set(epochs.info['ch_names'])\n",
    "    elecs_to_remove=get_subject_bad_electrodes(Subject)\n",
    "    elecs_to_drop=curr_elecs_in_epochs_set.intersection(elecs_to_remove)\n",
    "\n",
    "    if len(elecs_to_drop)>0:\n",
    "        epochs.info['bads']=elecs_to_drop\n",
    "        epochs.drop_channels(epochs.info['bads'])\n",
    "        print('\\n###########################################################')\n",
    "        print(f'Removed: {elecs_to_drop} from the current selected electrodes: {curr_elecs_in_epochs_set} from the overall set of bad electrodes {elecs_to_remove}')\n",
    "        print('#############################################################')\n",
    "    \n",
    "        #filter bank related: \n",
    "        filter_bank_epochs_after_elec_drops=[]\n",
    "        for curr_epochs in filter_bank_epochs:\n",
    "            curr_epochs.info['bads']=elecs_to_drop\n",
    "            curr_epochs.drop_channels(epochs.info['bads'])\n",
    "            filter_bank_epochs_after_elec_drops.append(curr_epochs)    \n",
    "    else: \n",
    "        #filter bank related: \n",
    "        filter_bank_epochs_after_elec_drops=[]\n",
    "        for curr_epochs in filter_bank_epochs:\n",
    "            filter_bank_epochs_after_elec_drops.append(curr_epochs)  \n",
    "\n",
    "        print('\\n###########################################################')\n",
    "        print(f'the current selected electrodes: {curr_elecs_in_epochs_set} allready exclude the requested electrodes to remove {elecs_to_remove}')\n",
    "        print('#############################################################')\n",
    "\n",
    "    #extract the validation set: we will use it only after selecting all hyper paramaters to get a better representation of out-of-sample performence: \n",
    "    #using a very small test size as we currently mostly look at the CV scores: \n",
    "    data_df=pd.DataFrame(data=epochs.events[:, -1], columns=['label'] ,index=range(len(epochs.events[:, -1])))\n",
    "    data_df['original_trial_ind']=range(len(epochs.events[:, -1]))\n",
    "    train,validation=train_test_split(data_df,shuffle=True,random_state=42,stratify=data_df['label'],test_size=0.2)\n",
    " \n",
    "    train_inds=train['original_trial_ind'].values\n",
    "    validation_inds=validation['original_trial_ind'].values\n",
    "    print(f'putting aside 20% of the data: trial numbers are:\\n {validation_inds}\\n')\n",
    "    print(f'remaining 80% of the trials go into training for cv:\\n {train_inds}\\n')\n",
    "\n",
    "    return_dict={'train_inds':train_inds,\n",
    "                'validation_inds':validation,\n",
    "                'epochs':epochs,\n",
    "                'filter_bank_epochs':filter_bank_epochs_after_elec_drops,\n",
    "                'events_triggers_dict':events_trigger_dict}\n",
    "    return train_inds,validation_inds,return_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_the_data(epochs,train_inds,validation_inds,full_epoch_tmin=0,full_epoch_tmax=4,tmin=1,tmax=2):\n",
    "    #returns a dictionary containing the cropped and uncropped versions of the validation and training epochs.\n",
    "    tmin=float(tmin)\n",
    "    tmax=float(tmax)\n",
    "    #save uncropped versions of the data: \n",
    "    #save the training data:\n",
    "    train_set_data_uncroped=epochs.get_data()[train_inds]\n",
    "    train_set_labels_uncroped=epochs.events[train_inds,-1]\n",
    "\n",
    "    #save the validation data: \n",
    "    validation_set_data_uncroped=epochs.get_data()[validation_inds]\n",
    "    validation_Set_labels_uncroped=epochs.events[validation_inds,-1]\n",
    "\n",
    "    #crop the epochs (use the epochs structure)\n",
    "    epochs_cropped = epochs.copy().crop(tmin=full_epoch_tmin, tmax=full_epoch_tmax)\n",
    "\n",
    "    #from here on - we extract the data as matrices (not epoch object anymore):\n",
    "\n",
    "    #save the training data:\n",
    "    train_set_data=epochs_cropped.get_data()[train_inds]\n",
    "    train_set_labels=epochs_cropped.events[train_inds,-1]\n",
    "\n",
    "    #save the validation data: \n",
    "    validation_set_data=epochs_cropped.get_data()[validation_inds]\n",
    "    validation_set_labels=epochs_cropped.events[validation_inds,-1]\n",
    "\n",
    "    return_dict={'train_set_data_uncroped':train_set_data_uncroped,\n",
    "                'train_set_labels_uncroped':train_set_labels_uncroped,\n",
    "                'validation_set_data_uncroped':validation_set_data_uncroped,\n",
    "                'validation_Set_labels_uncroped':validation_Set_labels_uncroped,\n",
    "                'epochs_cropped':epochs_cropped,\n",
    "                'train_set_data':train_set_data,\n",
    "                'train_set_labels':train_set_labels,\n",
    "                'validation_set_data':validation_set_data,\n",
    "                'validation_set_labels':validation_set_labels}\n",
    "    return return_dict\n",
    "\n",
    "def plot_accuracy_over_time(scores_windows,w_times,params_dict,axes_handle):\n",
    "    #this function accepts the scores windows (a list of n folds - each giving a score on a time window)\n",
    "    #it converts it to a long dataframe with the following columns: fold_id,Time,Accuracy\n",
    "    #then it uses the long format to plot using seaborn lineplot and get a confidence interval\n",
    "    times_col_names=[np.round(w_times[s],2) for s in range(len(w_times))]\n",
    "    scores_windows_array=np.squeeze(np.array(scores_windows))\n",
    "    scores_windows_df=pd.DataFrame(columns=times_col_names,data=scores_windows_array)\n",
    "    scores_windows_df['fold_id']=range(len(scores_windows_df))\n",
    "    longform_scores_windows_df=pd.melt(scores_windows_df, id_vars='fold_id', value_vars=scores_windows_df.columns)\n",
    "    longform_scores_windows_df.rename(columns={'variable':'Time','value':'Accuracy'},inplace=True)\n",
    "    sns.lineplot(data=longform_scores_windows_df,x='Time',y='Accuracy',ax=axes_handle)\n",
    "\n",
    "    if any(w_times>0):\n",
    "        onset_location=np.round(w_times[w_times>=0][0],2) ## find the onest (assuming 0 in epoch time)\n",
    "        axes_handle.axvline(onset_location, linestyle='--', color='k', label='Onset') \n",
    "        axes_handle.axvline(onset_location+1, linestyle=':', color='k', label='ArrowGone') ## adjusted 'Onset' to 3 seconds for augmented data\n",
    "    axes_handle.axhline(0.5, linestyle='-', color='k', label='Chance')\n",
    "    axes_handle.set_xlabel('time (s)')\n",
    "    axes_handle.set_ylabel('classification accuracy')\n",
    "    axes_handle.set_title('Classification score over time')\n",
    "    axes_handle.set_ylim([0.25, 0.9])\n",
    "    \n",
    "def run_windowed_classification_on_fold(fold_train_data_x,fold_train_data_y,fold_test_data_x_uncroped,fold_test_data_y,params_dict,w_start,w_length):\n",
    "    #note that this is currently the  function that really does the classification and extracts the performence measure (the previous calls to run_lda.... for example, are just tests)\n",
    "    curr_classifier_name=params_dict['pipeline_name']\n",
    "    if curr_classifier_name=='csp+lda':  \n",
    "        #define the classifier components:  \n",
    "        lda = LinearDiscriminantAnalysis()\n",
    "        csp = CSP(n_components=params_dict['n_components'], reg=None, log=True, norm_trace=False)\n",
    "        #define the pipeline: \n",
    "        clf = Pipeline([('csp',csp),('classifier_LDA',lda)])\n",
    "    elif curr_classifier_name=='csp+svm':\n",
    "        #define the classifier components:  \n",
    "        csp = CSP(n_components=params_dict['n_components'], reg=None, log=True, norm_trace=False)\n",
    "        #define the pipeline: \n",
    "        clf = Pipeline([('csp',csp), ('ovo_svm', OneVsOneClassifier(SVC(kernel='linear', random_state=42)))])\n",
    "    elif curr_classifier_name=='ts+svm':\n",
    "        #define the classifier components:  \n",
    "        covest = Covariances()\n",
    "        ts = TangentSpace()\n",
    "        lda = LinearDiscriminantAnalysis()\n",
    "        #define the pipeline: \n",
    "        clf = Pipeline([('conv',covest),('ts', ts),('ovo_svm', OneVsOneClassifier(SVC(kernel='linear', random_state=42)))])\n",
    "    elif curr_classifier_name=='ts+lda':\n",
    "        #define the classifier components:  \n",
    "        covest = Covariances()\n",
    "        ts = TangentSpace()\n",
    "        lda = LinearDiscriminantAnalysis()\n",
    "        #define the pipeline: \n",
    "        clf = Pipeline([('conv',covest),('ts', ts), ('ovo_svm', OneVsOneClassifier(SVC(kernel='linear', random_state=42)))])\n",
    "    elif curr_classifier_name=='fbcsp+lda':\n",
    "        #define the classifier components: \n",
    "        lda = LinearDiscriminantAnalysis()\n",
    "        csp = CSP(n_components=params_dict['n_components_fbcsp'], reg=None, log=True, norm_trace=False)\n",
    "        fb=FilterBank(csp)\n",
    "        #define the pipeline: \n",
    "        clf = Pipeline([('fbcsp',fb),('classifier_LDA',lda)])\n",
    "    else: \n",
    "      \n",
    "        raise Exception(f'the requested classifier is not defined in \"run_windowed_classification_on_fold\": {curr_classifier_name}')\n",
    "    A, B  = 'Left', 'Right'  # Replace with actual trigger names/values\n",
    "\n",
    "    #get string labels instead of numeric (so the classifier will have an informative clf.classes_ )\n",
    "    triggers_label_dict={val:key for key,val in params_dict['preprocessing_dict']['events_triggers_dict'].items()} \n",
    "    fold_train_data_y_labels=np.array([triggers_label_dict[cur_y] for cur_y in fold_train_data_y])  \n",
    "    combined_labels_train = np.array(['motor_imagery' if label in [A, B] else 'rest' for label in fold_train_data_y_labels])\n",
    "\n",
    "    #fit the selected classifier: \n",
    "    \n",
    "    # clf.fit(fold_train_data_x, fold_train_data_y_labels)\n",
    "    clf.fit(fold_train_data_x, combined_labels_train)\n",
    "    # running classifier: test classifier on sliding window\n",
    "\n",
    "    #get string labels instead of numeric for the test\n",
    "    fold_test_data_y_labels=np.array([triggers_label_dict[cur_y] for cur_y in fold_test_data_y])\n",
    "    # fold_windowed_scores,confusion_metrices_per_window=run_windowed_pretrained_classifier(clf,fold_test_data_x_uncroped,fold_test_data_y_labels,w_start,w_length)\n",
    "\n",
    "    combined_labels_test = np.array(['motor_imagery' if label in [A, B] else 'rest' for label in fold_test_data_y_labels])\n",
    "    fold_windowed_scores,confusion_metrices_per_window=run_windowed_pretrained_classifier(clf,fold_test_data_x_uncroped,combined_labels_test,w_start,w_length)\n",
    "    return fold_windowed_scores,confusion_metrices_per_window,clf\n",
    "\n",
    "def run_windowed_pretrained_classifier(clf,x_uncropped,y,w_start,w_length):\n",
    "    scores_per_time_window = []\n",
    "    confusion_metrices_per_window=[]\n",
    "    if len(x_uncropped.shape)==3: #reshape it as if it was a 4d matrix (assuming the 4th dimention is the filterbank)\n",
    "        x_uncropped=x_uncropped.reshape(list(x_uncropped.shape)+[1])\n",
    "    for n in w_start:\n",
    "        fold_data=np.squeeze(x_uncropped[:, :, n:(n + w_length),:]) #using squeeze here so that if the 4th dimention size is 1 it will reduce it to a 3d vector\n",
    "        #if the classifier uses a filterbank its input should be 4d (trials,channels,timesteps,filter_bands) and if it doesnt its 3d (trials,channels,timesteps)\n",
    "        fold_score_on_time_window=clf.score(fold_data, y)\n",
    "        #append the score for the LDA, using this csp to predict the relevant test scores: \n",
    "        scores_per_time_window.append(fold_score_on_time_window)\n",
    "        confusion_mat=confusion_matrix(y,clf.predict(fold_data),labels=clf.classes_)\n",
    "        confusion_metrices_per_window.append(confusion_mat)\n",
    "    return scores_per_time_window,confusion_metrices_per_window\n",
    "\n",
    "def augment_data(augmentation_params,data_x_to_augment,y,sfreq):\n",
    "    #do augmentation: \n",
    "    if (augmentation_params['win_step']==0 or augmentation_params['win_len']==0): #check if augmentation is not requested/invalid:\n",
    "        augmented_x=data_x_to_augment\n",
    "        augmented_y=y\n",
    "    else: #augmentation requested\n",
    "        #set up the augmentation window boundaries based on the augmentation paramaters:                      \n",
    "        aug_epochs_s=np.arange(0,data_x_to_augment.shape[2],augmentation_params['win_step']*sfreq)\n",
    "        aug_epochs_e=np.array([a+augmentation_params['win_len']*sfreq for a in aug_epochs_s])\n",
    "        #remove start and ends that exceeds the relevant epoch lengths: \n",
    "        aug_epochs_s=aug_epochs_s[aug_epochs_e<data_x_to_augment.shape[2]]\n",
    "        aug_epochs_e=aug_epochs_e[aug_epochs_e<data_x_to_augment.shape[2]]\n",
    "\n",
    "        #pile all augmented (sub windows) to have the regular structure of epochs (>original due to augmentation,channels,samples)\n",
    "        data_fold_x_augmented=[]\n",
    "        data_fold_y_augmented=[]\n",
    "        for aug_s,aug_e in zip(aug_epochs_s,aug_epochs_e):\n",
    "            if len(data_x_to_augment.shape)==3:\n",
    "                data_x_in_cur_window=data_x_to_augment[:,:,int(aug_s):int(aug_e)]\n",
    "            elif len(data_x_to_augment.shape)==4: #with filterbank: \n",
    "                data_x_in_cur_window=data_x_to_augment[:,:,int(aug_s):int(aug_e),:]\n",
    "            data_y_in_cur_window=y\n",
    "            data_fold_x_augmented.append(data_x_in_cur_window)\n",
    "            data_fold_y_augmented.append(data_y_in_cur_window)\n",
    "\n",
    "        augmented_x=np.concatenate(data_fold_x_augmented,axis=0)\n",
    "        augmented_y=np.concatenate(data_fold_y_augmented)\n",
    "    return augmented_x,augmented_y\n",
    "\n",
    "\n",
    "def run_windowed_classification_aug_cv(epochs_cropped,cv_split,train_set_data,train_set_labels,train_set_data_uncroped,params_dict):\n",
    "    augmentation_params=params_dict['augmentation_params']\n",
    "    windowed_prediction_params=params_dict['windowed_prediction_params']\n",
    "    win_len=windowed_prediction_params['win_len']\n",
    "    win_step=windowed_prediction_params['win_step']\n",
    "    \n",
    "    sfreq = epochs_cropped.info['sfreq']\n",
    "    w_length = int(sfreq * win_len)   # running classifier: window length\n",
    "    w_step = int(sfreq * win_step)  # running classifier: window step size\n",
    "    w_start = np.arange(0, train_set_data_uncroped.shape[2] - w_length, w_step)\n",
    "    print('uncroped train set length = ',train_set_data_uncroped.shape[2])\n",
    "\n",
    "    scores_windows = []\n",
    "    folds_confusion_metrices_per_window=[]\n",
    "    #this section first extracts each CV fold, only then it augments it (to avoid data leakage)\n",
    "    for train_idx, test_idx in cv_split:\n",
    "        #seperate the cv fold for labels - train-test:\n",
    "        y_train, y_test = train_set_labels[train_idx], train_set_labels[test_idx] \n",
    "        #seperate the cv fold for features information: \n",
    "        if len(train_set_data.shape)==3:\n",
    "            data_fold_x_train_to_augment = train_set_data[train_idx,:,:]\n",
    "        elif len(train_set_data.shape)==4: #there are filter bank info in the data: \n",
    "            data_fold_x_train_to_augment = train_set_data[train_idx,:,:,:] \n",
    "        #do augmentation: \n",
    "        augmented_x,augmented_y=augment_data(augmentation_params,data_fold_x_train_to_augment,y_train,sfreq)\n",
    "        #run classifier on the data fold\n",
    "        curr_scores_windows,confusion_metrices_per_window,_=run_windowed_classification_on_fold(augmented_x,augmented_y,train_set_data_uncroped[test_idx],y_test,params_dict,w_start,w_length)         \n",
    "        scores_windows.append(curr_scores_windows)\n",
    "        folds_confusion_metrices_per_window.append(confusion_metrices_per_window)\n",
    "    w_times = (w_start + w_length / 2.) / sfreq + params_dict['epoch_tmin']\n",
    "    return scores_windows,folds_confusion_metrices_per_window,w_times\n",
    "\n",
    "\n",
    "def run_windowed_classification_aug(epochs_cropped,train_set_data,train_set_labels,train_set_data_uncroped,test_y,params_dict):\n",
    "    augmentation_params=params_dict['augmentation_params']\n",
    "    windowed_prediction_params=params_dict['windowed_prediction_params']\n",
    "    win_len=windowed_prediction_params['win_len']\n",
    "    win_step=windowed_prediction_params['win_step']\n",
    "    sfreq = epochs_cropped.info['sfreq']\n",
    "    w_length = int(sfreq * win_len)   # running classifier: window length\n",
    "    w_step = int(sfreq * win_step)  # running classifier: window step size\n",
    "    w_start = np.arange(0, train_set_data_uncroped.shape[2] - w_length, w_step)\n",
    "    w_times = (w_start + w_length / 2.) / sfreq + params_dict['epoch_tmin']\n",
    "\n",
    "    augmented_x,augmented_y=augment_data(augmentation_params,train_set_data,train_set_labels,sfreq)\n",
    "    scores_windows,confusion_metrices_per_window,trained_clf=run_windowed_classification_on_fold(augmented_x,augmented_y,train_set_data_uncroped,test_y,params_dict,w_start,w_length)         \n",
    "\n",
    "    return scores_windows,confusion_metrices_per_window,w_times,trained_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training_and_classification_on_selected_params(params_dict,preprocessing_dict,to_plot=False,figure_outputs_path='',fig_name='temp'):\n",
    "    epochs_copy=preprocessing_dict['epochs']\n",
    "    train_inds=preprocessing_dict['train_inds']\n",
    "    validation_inds=preprocessing_dict['validation_inds']['original_trial_ind'].values\n",
    "\n",
    "    #crop the data according to the training window: \n",
    "    returned_dict=crop_the_data(epochs_copy,train_inds,validation_inds,params_dict['classifier_window_s'],params_dict['classifier_window_e']) #two more paramters here are tmin and tmax which are not used apparently. \n",
    "    train_set_data_uncropped=returned_dict['train_set_data_uncroped']\n",
    "    epochs_cropped=returned_dict['epochs_cropped']\n",
    "    train_set_data=returned_dict['train_set_data']\n",
    "    train_set_labels=returned_dict['train_set_labels']\n",
    "\n",
    "    validation_set_labels=returned_dict['validation_set_labels']\n",
    "    validation_set_data_uncropped=returned_dict['validation_set_data_uncroped']\n",
    "    #define cv on the data: \n",
    "    cv = StratifiedShuffleSplit(10, test_size=0.2, random_state=42)\n",
    "    cv_split = cv.split(train_set_data,train_set_labels)\n",
    "\n",
    "    #filter bank related:\n",
    "    if params_dict['pipeline_name']=='fbcsp+lda': \n",
    "        train_set_data_fb=[]\n",
    "        train_set_data_uncropped_fb=[]\n",
    "        validation_set_data_fb=[]\n",
    "        validation_set_data_uncropped_fb=[]\n",
    "        for filtered_data_band_epoch in preprocessing_dict['filter_bank_epochs']:\n",
    "            returned_dict_temp=crop_the_data(filtered_data_band_epoch,train_inds,validation_inds, params_dict['classifier_window_s'],params_dict['classifier_window_e'])\n",
    "            #extract the train set data: \n",
    "            train_set_data_uncroped_temp=returned_dict_temp['train_set_data_uncroped']\n",
    "            train_set_data_temp=returned_dict_temp['train_set_data']\n",
    "            train_set_data_fb.append(train_set_data_temp)\n",
    "            train_set_data_uncropped_fb.append(train_set_data_uncroped_temp)\n",
    "            #extract the validation set data: \n",
    "            validation_set_data_uncroped_temp=returned_dict_temp['validation_set_data_uncroped']\n",
    "            validation_set_data_temp=returned_dict_temp['validation_set_data']\n",
    "            validation_set_data_fb.append(validation_set_data_temp)\n",
    "            validation_set_data_uncropped_fb.append(validation_set_data_uncroped_temp)\n",
    "        #create a 4d matrix of train data:     \n",
    "        train_set_data_4d_array= np.transpose(np.array(train_set_data_fb),(1,2,3,0))\n",
    "        train_set_data_uncropped_4d_array=np.transpose(np.array(train_set_data_uncropped_fb),(1,2,3,0)) \n",
    "        train_set_data=train_set_data_4d_array\n",
    "        train_set_data_uncropped=train_set_data_uncropped_4d_array\n",
    "        #create a 4d matrix of validation data: \n",
    "        validation_set_data_4d_array= np.transpose(np.array(validation_set_data_fb),(1,2,3,0))\n",
    "        validation_set_data_uncropped_4d_array=np.transpose(np.array(validation_set_data_uncropped_fb),(1,2,3,0)) \n",
    "        validation_set_data_uncropped=validation_set_data_uncropped_4d_array\n",
    "\n",
    "    #get scores over time using CV: \n",
    "    scores_windows,folds_confusion_metrices_per_window,w_times=run_windowed_classification_aug_cv(epochs_cropped,cv_split,train_set_data,train_set_labels,train_set_data_uncropped,params_dict)\n",
    "    \n",
    "    #train the classifier based on ALL training data, and test its prediction on the unseen validation set: \n",
    "    validaiton_scores,validation_confusion_metrices_per_window,_,trained_clf=run_windowed_classification_aug(epochs_cropped,train_set_data,train_set_labels,validation_set_data_uncropped,validation_set_labels,params_dict)\n",
    "    if to_plot:\n",
    "        fig,axes=plt.subplots(nrows=1,ncols=2)\n",
    "        plot_accuracy_over_time(scores_windows,w_times,params_dict,axes_handle=axes[0])\n",
    "        epochs_copy.plot_sensors(show_names=True,axes=axes[1])\n",
    "        figname=fig_name + '.svg'\n",
    "        fig.savefig(figure_outputs_path / figname)\n",
    "    else:\n",
    "        fig=[]\n",
    "    return fig,w_times,scores_windows,folds_confusion_metrices_per_window,validaiton_scores,validation_confusion_metrices_per_window,trained_clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_grid_search_on_single_participant(grid_search_dict,recording_file,Subject,save_every_n_iter,save_location_path,to_plot=True):\n",
    "    all_options=[list(range(len(val))) for key,val in grid_search_dict.items()]\n",
    "    #get all possible grid_search combinations: \n",
    "    all_grid_combinations = list(itertools.product(*all_options))\n",
    "    print(f'number of grid search iterations: {len(all_grid_combinations)}')\n",
    "\n",
    "    grid_search_data_frame_info=pd.DataFrame()\n",
    "    print('running grid search on:',recording_file)\n",
    "    #put all in a single params_dictionary for the current run: \n",
    "    #run all grid_search iterations: \n",
    "    for iteration_ind in tqdm(range(len(all_grid_combinations))):\n",
    "        #extract current iteration paramaters:\n",
    "        params_dict=set_up_params_for_current_grid_iteration(all_grid_combinations,iteration_ind,grid_search_dict)\n",
    "        \n",
    "        #add subject specific information: \n",
    "        params_dict['recording_file']=recording_file\n",
    "        params_dict['subject']=Subject\n",
    "        print(f'test iteration: dictionary paramaters: {params_dict}')\n",
    "        #run preprocessing:\n",
    "        train_inds,validation_inds,preprocessing_dict=run_pre_processing_extract_validation_set(recording_path,current_path,params_dict)\n",
    "        #run prediction on cross validation:\n",
    "        fig,w_times,scores_windows,validation_scores=run_training_and_classification_on_selected_params(params_dict,preprocessing_dict,to_plot=to_plot,figure_outputs_path=figure_outputs_path,fig_name='test')\n",
    "        #train the model on all the training data: \n",
    "        #   tbd\n",
    "        #run prediction on the validation set(?)\n",
    "        #   tbd\n",
    "        #add scores related information: \n",
    "        curr_params_df=pd.DataFrame([params_dict],index=[iteration_ind])\n",
    "        curr_params_df['mean_scores']=np.nan\n",
    "        curr_params_df['std_scores']=np.nan\n",
    "        curr_params_df['mean_scores']=curr_params_df['mean_scores'].astype(object)\n",
    "        curr_params_df['std_scores']=curr_params_df['mean_scores'].astype(object)\n",
    "        curr_params_df['mean_scores']=[np.mean(scores_windows,axis=1)]\n",
    "        curr_params_df['std_scores']=[np.std(scores_windows,axis=1)]\n",
    "        grid_search_data_frame_info=pd.concat([grid_search_data_frame_info,curr_params_df],axis=0)\n",
    "        df_name='hypter_param_search_' + recording_file.split('.')[0] + '.csv'\n",
    "        if np.mod(iteration_ind,save_every_n_iter)==0:\n",
    "            print('saving')\n",
    "            grid_search_data_frame_info.to_csv(hyper_param_search_output / df_name)\n",
    "\n",
    "    #save all grid_search results: \n",
    "    grid_search_data_frame_info.to_csv(hyper_param_search_output / df_name)\n",
    "    return grid_search_data_frame_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combined_preprocessing_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m inds\u001b[38;5;241m=\u001b[39m\u001b[43mcombined_preprocessing_dict\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_inds\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      2\u001b[0m labels\u001b[38;5;241m=\u001b[39mcombined_preprocessing_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mevents[inds, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      3\u001b[0m decision_function\u001b[38;5;241m=\u001b[39mtrained_clf\u001b[38;5;241m.\u001b[39mdecision_function(combined_preprocessing_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy()\u001b[38;5;241m.\u001b[39mcrop(tmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,tmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mget_data()[inds,:])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'combined_preprocessing_dict' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "inds=combined_preprocessing_dict['train_inds']\n",
    "labels=combined_preprocessing_dict['epochs'].events[inds, -1]\n",
    "decision_function=trained_clf.decision_function(combined_preprocessing_dict['epochs'].copy().crop(tmin=0.5,tmax=1).get_data()[inds,:])\n",
    "y_score=decision_function\n",
    "classes_numeric_list=list(combined_preprocessing_dict['events_triggers_dict'].values())\n",
    "classes_names_list=list(combined_preprocessing_dict['events_triggers_dict'].keys())\n",
    "# Determine the unique classes in the labels\n",
    "unique_classes = np.unique(labels)\n",
    "n_classes = len(unique_classes)\n",
    "\n",
    "Y = label_binarize(labels, classes=unique_classes)\n",
    "Y = np.hstack((Y, 1 - Y))\n",
    "n_classes = Y.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.82437038,  2.55558762,  2.37073506, -1.86941927,  1.82724807,\n",
       "       -0.67607585, -2.11435307,  0.79981566,  1.76325851,  3.23950003,\n",
       "        5.12996444, -4.16897121,  5.89769517, -3.77737568,  8.40484384,\n",
       "        3.70981675,  2.60278754,  1.19453563, -1.14500389, -0.60113286,\n",
       "       -6.28051383, -3.30907892, -2.52827281,  1.39377374,  3.25686043,\n",
       "        2.59327406, -2.25295498,  5.77866525, -3.03182234,  1.90473949,\n",
       "        0.19570973,  1.46143522,  3.03154848, 10.94035814, -1.57485594,\n",
       "        0.35714107, -2.4227413 ,  4.08704169,  0.59838216, -6.49431661,\n",
       "        4.88058117,  0.70907885,  3.13002725, -3.98126859,  1.00198414,\n",
       "       -0.99937072,  0.95210008, -0.47971726,  4.7764562 , -1.93023989,\n",
       "        0.69821926,  3.19083572, -5.39751934,  5.46590436, -2.14943658,\n",
       "        3.55562444,  2.84386729,  6.05080781, -4.54374263,  1.51540612,\n",
       "       -1.91873738,  2.74681034,  0.07042497, -2.73303037, -6.137496  ,\n",
       "        4.45176556, -6.7857344 , -1.57854058,  3.05652611,  4.93681458,\n",
       "        0.51957196, -5.47134839, -2.85340193, -0.97819998,  1.52579378,\n",
       "        3.04860307,  0.10487688, -5.58333896,  0.94348039,  0.19288112,\n",
       "        0.93478568, -9.04389566, -8.4138125 ,  5.50714519, -0.89541078,\n",
       "       -0.88294206,  0.68133155,  4.4031748 ,  1.88855108, -2.18601159,\n",
       "       -3.98582401,  1.22742403, -1.37582736,  8.70617176, -5.3155066 ,\n",
       "       -4.54421695])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall_curves_from_trained_classifier(preprocessing_dict,params_dict,precision_recall_curve_timerange,trained_clf,predict_validation=True):\n",
    "    #to learn on precision recall curves see :https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html \n",
    "    #the code is adapated for our usage: \n",
    "    #prepreocessing_dict - dictionary that contains the {original epoched data, and the training/validation indexes}\n",
    "    #params_dict - dictionary that contains the prediction paramaters\n",
    "    #precision_Revall_curve_timerange - list #in seconds relative to epoch (so if epoch is -3 to +4, 3-4 will take the last second in the epoch )\n",
    "    #trained_clf - the classifier that was previously trained on all the data: (note that this means that the report here is biased (better than really is))\n",
    "    #predict_validation - true - will use only validation indexes, false - will use only training indexes (much more biased ofcourse) \n",
    "    \n",
    "    #define what time_range you want to extract the recall/precision for: \n",
    "    print(f'chosen window prediction range is {precision_recall_curve_timerange}\\nnote that the prediction paramaters (that the classifier is trained on) are: {params_dict[\"windowed_prediction_params\"]}\\nconsider if you want the preciction range to match the prediction_param')\n",
    "    \n",
    "    #decide if we use the training or the validation set to plot: \n",
    "    if predict_validation: \n",
    "    #get the relevant data for the validation set: \n",
    "        inds=preprocessing_dict['validation_inds']['original_trial_ind'].values\n",
    "    else:\n",
    "        inds=preprocessing_dict['train_inds']\n",
    "\n",
    "\n",
    "    #extract the labels: \n",
    "    labels=preprocessing_dict['epochs'].events[inds, -1]\n",
    "    #extract the decision function: \n",
    "\n",
    "    #fbcsp\n",
    "    if params_dict['pipeline_name']=='fbcsp+lda':\n",
    "        data_set_fb = []\n",
    "        for filtered_data_band_epoch in preprocessing_dict['filter_bank_epochs']:\n",
    "            temp_data = filtered_data_band_epoch.copy().crop(tmin=precision_recall_curve_timerange[0],tmax=precision_recall_curve_timerange[1]).get_data()[:]\n",
    "            data_set_fb.append(temp_data)\n",
    "        data_set_fb_4d_array= np.transpose(np.array(data_set_fb),(1,2,3,0))\n",
    "        decision_function=trained_clf.decision_function((data_set_fb_4d_array)[inds,:])\n",
    "    else:\n",
    "            decision_function=trained_clf.decision_function(preprocessing_dict['epochs'].copy().crop(tmin=precision_recall_curve_timerange[0],tmax=precision_recall_curve_timerange[1]).get_data()[inds,:])\n",
    "    y_score=decision_function\n",
    "    # Use label_binarize to be multi-label like settings (basicly the current label position is 1 and rest are 0): \n",
    "    #so the label list of say, 0 2 4 4 will output = [1,0,0],[0,1,0],[0,0,1],[0,0,1]\n",
    "    classes_numeric_list=list(preprocessing_dict['events_triggers_dict'].values())\n",
    "    classes_names_list=list(preprocessing_dict['events_triggers_dict'].keys())\n",
    "    #take the classes from the preprocessing dict:\n",
    "    Y = label_binarize(labels, classes=classes_numeric_list)\n",
    "    n_classes = Y.shape[1]\n",
    "\n",
    "    #calculate precision and recall for each class\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    average_precision = dict()\n",
    "    thresholds=dict()\n",
    "    if n_classes==1: #in a binary setting where the score is only relates to being in group \"1\" (or maybe 0, worth checking)\n",
    "        precision[0], recall[0], thresholds[0]  = precision_recall_curve(Y, y_score)\n",
    "        average_precision[0] = average_precision_score(Y, y_score)\n",
    "    else: \n",
    "        for i in range(n_classes):\n",
    "            precision[i], recall[i], thresholds[i] = precision_recall_curve(Y[:, i], y_score[:, i])\n",
    "            average_precision[i] = average_precision_score(Y[:, i], y_score[:, i])\n",
    "\n",
    "    # A \"micro-average\": quantifying score on all classes jointly\n",
    "    precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(Y.ravel(), y_score.ravel())\n",
    "    average_precision[\"micro\"] = average_precision_score(Y, y_score, average=\"micro\")\n",
    "\n",
    "    # setup plot details\n",
    "    colors = cycle([\"navy\", \"turquoise\", \"darkorange\", \"cornflowerblue\", \"teal\"])\n",
    "\n",
    "    _, ax = plt.subplots(figsize=(7, 8))\n",
    "\n",
    "    f_scores = np.linspace(0.2, 0.8, num=4)\n",
    "    lines, labels = [], []\n",
    "    for f_score in f_scores:\n",
    "        x = np.linspace(0.01, 1)\n",
    "        y = f_score * x / (2 * x - f_score)\n",
    "        (l,) = plt.plot(x[y >= 0], y[y >= 0], color=\"gray\", alpha=0.2)\n",
    "        plt.annotate(\"f1={0:0.1f}\".format(f_score), xy=(0.9, y[45] + 0.02))\n",
    "\n",
    "    display = PrecisionRecallDisplay(\n",
    "        recall=recall[\"micro\"],\n",
    "        precision=precision[\"micro\"],\n",
    "        average_precision=average_precision[\"micro\"],\n",
    "    )\n",
    "    display.plot(ax=ax, name=\"Micro-average precision-recall\", color=\"gold\")\n",
    "\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        display = PrecisionRecallDisplay(\n",
    "            recall=recall[i],\n",
    "            precision=precision[i],\n",
    "            average_precision=average_precision[i],\n",
    "        )\n",
    "        display.plot(ax=ax, name=f\"Precision-recall for class {classes_names_list[i]}\", color=color)\n",
    "\n",
    "    # add the legend for the iso-f1 curves\n",
    "    handles, labels = display.ax_.get_legend_handles_labels()\n",
    "    handles.extend([l])\n",
    "    labels.extend([\"iso-f1 curves\"])\n",
    "    # set the legend and the axes\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.legend(handles=handles, labels=labels, loc=\"best\")\n",
    "    ax.set_title(f\"multi-class Precision-Recall curve\\npredicted time range: {precision_recall_curve_timerange}\")\n",
    "\n",
    "    plt.show()\n",
    "    #create a dataframe with all information relevant to the plot. \n",
    "    precision.pop('micro')\n",
    "    precision_df=pd.DataFrame(precision)\n",
    "    precision_df.columns=['precision_'+str(colname) for colname in precision_df.columns] \n",
    "    recall.pop('micro')\n",
    "    recall_df=pd.DataFrame(recall)\n",
    "    recall_df.columns=['recall_'+str(colname) for colname in recall_df.columns]\n",
    "    thresholds_df=pd.DataFrame(thresholds)\n",
    "    thresholds_df.columns=['thresholds'+str(colname) for colname in thresholds_df.columns]\n",
    "\n",
    "    return_df=pd.concat([precision_df,recall_df,thresholds_df],axis=1)\n",
    "\n",
    "\n",
    "    return return_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessing_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[43mpreprocessing_dict\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevents_triggers_dict\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys()))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preprocessing_dict' is not defined"
     ]
    }
   ],
   "source": [
    "len(list(preprocessing_dict['events_triggers_dict'].keys()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## single participant single grid-iteration: \n",
    "### in the next cell we define a specific iteration on a specific participant from the grid and run it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NH_Block_1.xdf', 'NH_Block_2.xdf', 'NH_Block_3.xdf']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording_files[9:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neta_AO_2Hands.xdf', 'Neta_NoAO_1Hand.xdf', 'Neta_NoAO_2Hands.xdf']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording_files[6:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NH_Block_1.xdf NH\n",
      "NH_Block_2.xdf NH\n",
      "setting up current params: iteration 0 - grid settings: (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n",
      "NH_Block_1.xdf NH\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=67, n_times=333262\n",
      "    Range : 0 ... 333261 =      0.000 ...   666.522 secs\n",
      "Ready.\n",
      "\n",
      "###########################################################\n",
      "removing subject sepecific bad electrodes from the raw data\n",
      "\n",
      "###########################################################\n",
      "removing bad channels from epochs:\n",
      "\n",
      "###########################################################\n",
      "running csd\n",
      "Fitted sphere radius:         95.0 mm\n",
      "Origin head coordinates:      0.0 -0.0 0.0 mm\n",
      "Origin device coordinates:    0.0 -0.0 0.0 mm\n",
      "\n",
      "###########################################################\n",
      "filtering the data\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 8 - 32 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 8.00, 32.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 8 - 12 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 8.00, 12.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 12 - 20 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 12.00, 20.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 20 - 28 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 20.00, 28.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 28 - 32 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 28.00, 32.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Used Annotations descriptions: ['Beep', 'Experiment Ended', 'Left', 'Long Break', 'Rest', 'Resting', 'Right']\n",
      "\n",
      "###########################################################\n",
      "extracting event info: {'Beep': 1, 'Experiment Ended': 2, 'Left': 3, 'Long Break': 4, 'Rest': 5, 'Resting': 6, 'Right': 7}\n",
      "\n",
      "###########################################################\n",
      "Not setting metadata\n",
      "40 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 40 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "40 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 40 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "40 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 40 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "40 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 40 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "epoching + selecting current electodes set for analysis:\n",
      "['FC5', 'FC3', 'FC1', 'FC2', 'FC4', 'FC6', 'FT7', 'FT8', 'C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6', 'CP5', 'CP3', 'CP1', 'CPz', 'CP2', 'CP4', 'CP6']\n",
      "Not setting metadata\n",
      "40 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 40 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "\n",
      "###########################################################\n",
      "removing bad channels from epochs:\n",
      "\n",
      "###########################################################\n",
      "the current selected electrodes: {'CPz', 'FC1', 'FC6', 'CP3', 'CP4', 'C1', 'FT8', 'CP1', 'CP5', 'C5', 'FC2', 'FT7', 'FC4', 'FC3', 'FC5', 'CP2', 'C6', 'C4', 'C3', 'C2', 'CP6', 'Cz'} allready exclude the requested electrodes to remove {'TP7'}\n",
      "#############################################################\n",
      "putting aside 20% of the data: trial numbers are:\n",
      " [16 30 35 19 15  3 24  2]\n",
      "\n",
      "remaining 80% of the trials go into training for cv:\n",
      " [26 38 22 33 17 20 29 10 28 23 12 27 21  0  4 32 13  7  6 37  8 11 34  9\n",
      " 14 18 39  5  1 31 25 36]\n",
      "\n",
      "NH_Block_2.xdf NH\n",
      "Creating RawArray with float64 data, n_channels=67, n_times=346498\n",
      "    Range : 0 ... 346497 =      0.000 ...   692.994 secs\n",
      "Ready.\n",
      "\n",
      "###########################################################\n",
      "removing subject sepecific bad electrodes from the raw data\n",
      "\n",
      "###########################################################\n",
      "removing bad channels from epochs:\n",
      "\n",
      "###########################################################\n",
      "running csd\n",
      "Fitted sphere radius:         95.0 mm\n",
      "Origin head coordinates:      0.0 -0.0 0.0 mm\n",
      "Origin device coordinates:    0.0 -0.0 0.0 mm\n",
      "\n",
      "###########################################################\n",
      "filtering the data\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 8 - 32 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 8.00, 32.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 8 - 12 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 8.00, 12.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 12 - 20 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 12.00, 20.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 20 - 28 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 20.00, 28.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 28 - 32 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 28.00, 32.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Used Annotations descriptions: ['Beep', 'Experiment Ended', 'Left', 'Long Break', 'Rest', 'Resting', 'Right']\n",
      "\n",
      "###########################################################\n",
      "extracting event info: {'Beep': 1, 'Experiment Ended': 2, 'Left': 3, 'Long Break': 4, 'Rest': 5, 'Resting': 6, 'Right': 7}\n",
      "\n",
      "###########################################################\n",
      "Not setting metadata\n",
      "40 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 40 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "40 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 40 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "40 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 40 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "40 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 40 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "epoching + selecting current electodes set for analysis:\n",
      "['FC5', 'FC3', 'FC1', 'FC2', 'FC4', 'FC6', 'FT7', 'FT8', 'C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6', 'CP5', 'CP3', 'CP1', 'CPz', 'CP2', 'CP4', 'CP6']\n",
      "Not setting metadata\n",
      "40 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 40 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "\n",
      "###########################################################\n",
      "removing bad channels from epochs:\n",
      "\n",
      "###########################################################\n",
      "the current selected electrodes: {'CPz', 'FC1', 'FC6', 'CP3', 'CP4', 'C1', 'FT8', 'CP1', 'CP5', 'C5', 'FC2', 'FT7', 'FC4', 'FC3', 'FC5', 'CP2', 'C6', 'C4', 'C3', 'C2', 'CP6', 'Cz'} allready exclude the requested electrodes to remove {'TP7'}\n",
      "#############################################################\n",
      "putting aside 20% of the data: trial numbers are:\n",
      " [16 29 33 21 15  7 22  1]\n",
      "\n",
      "remaining 80% of the trials go into training for cv:\n",
      " [25 38 18 35 17 24 26  6 30 20 12 28 27  0  8 32 13  4  3 34  5 11 36 10\n",
      " 14 19 39  9  2 31 23 37]\n",
      "\n",
      "NH_Block_3.xdf NH\n",
      "Creating RawArray with float64 data, n_channels=67, n_times=296047\n",
      "    Range : 0 ... 296046 =      0.000 ...   592.092 secs\n",
      "Ready.\n",
      "\n",
      "###########################################################\n",
      "removing subject sepecific bad electrodes from the raw data\n",
      "\n",
      "###########################################################\n",
      "removing bad channels from epochs:\n",
      "\n",
      "###########################################################\n",
      "running csd\n",
      "Fitted sphere radius:         95.0 mm\n",
      "Origin head coordinates:      0.0 -0.0 0.0 mm\n",
      "Origin device coordinates:    0.0 -0.0 0.0 mm\n",
      "\n",
      "###########################################################\n",
      "filtering the data\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 8 - 32 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 8.00, 32.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 8 - 12 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 8.00, 12.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 12 - 20 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 12.00, 20.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 20 - 28 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 20.00, 28.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 28 - 32 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 28.00, 32.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Used Annotations descriptions: ['Beep', 'Experiment Ended', 'Left', 'Long Break', 'Rest', 'Resting', 'Right']\n",
      "\n",
      "###########################################################\n",
      "extracting event info: {'Beep': 1, 'Experiment Ended': 2, 'Left': 3, 'Long Break': 4, 'Rest': 5, 'Resting': 6, 'Right': 7}\n",
      "\n",
      "###########################################################\n",
      "Not setting metadata\n",
      "40 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 40 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "40 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 40 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "40 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 40 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "40 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 40 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "epoching + selecting current electodes set for analysis:\n",
      "['FC5', 'FC3', 'FC1', 'FC2', 'FC4', 'FC6', 'FT7', 'FT8', 'C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6', 'CP5', 'CP3', 'CP1', 'CPz', 'CP2', 'CP4', 'CP6']\n",
      "Not setting metadata\n",
      "40 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 40 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "\n",
      "###########################################################\n",
      "removing bad channels from epochs:\n",
      "\n",
      "###########################################################\n",
      "the current selected electrodes: {'CPz', 'FC1', 'FC6', 'CP3', 'CP4', 'C1', 'FT8', 'CP1', 'CP5', 'C5', 'FC2', 'FT7', 'FC4', 'FC3', 'FC5', 'CP2', 'C6', 'C4', 'C3', 'C2', 'CP6', 'Cz'} allready exclude the requested electrodes to remove {'TP7'}\n",
      "#############################################################\n",
      "putting aside 20% of the data: trial numbers are:\n",
      " [14 31 32 22 12  2 21  1]\n",
      "\n",
      "remaining 80% of the trials go into training for cv:\n",
      " [27 39 15 34 18 24 28 11 29 19 13 26 25  0  4 33 16  9  6 38 10  8 35  7\n",
      " 17 20 37  5  3 30 23 36]\n",
      "\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "120 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "120 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "120 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "120 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "120 matching events found\n",
      "No baseline correction applied\n",
      "uncroped train set length =  3501\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "n_classes must be >= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 80\u001b[0m\n\u001b[0;32m     76\u001b[0m params_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessing_dict\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mpreprocessing_dict\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m#test it: \u001b[39;00m\n\u001b[1;32m---> 80\u001b[0m fig,w_times,scores_windows,folds_confusion_metrices_per_window,validation_scores,validation_confusion_metrices_per_window,trained_clf\u001b[38;5;241m=\u001b[39m\u001b[43mrun_training_and_classification_on_selected_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcombined_preprocessing_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43mto_plot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mfigure_outputs_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfigure_outputs_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfig_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 48\u001b[0m, in \u001b[0;36mrun_training_and_classification_on_selected_params\u001b[1;34m(params_dict, preprocessing_dict, to_plot, figure_outputs_path, fig_name)\u001b[0m\n\u001b[0;32m     45\u001b[0m     validation_set_data_uncropped\u001b[38;5;241m=\u001b[39mvalidation_set_data_uncropped_4d_array\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m#get scores over time using CV: \u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m scores_windows,folds_confusion_metrices_per_window,w_times\u001b[38;5;241m=\u001b[39m\u001b[43mrun_windowed_classification_aug_cv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs_cropped\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcv_split\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_set_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_set_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_set_data_uncropped\u001b[49m\u001b[43m,\u001b[49m\u001b[43mparams_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m#train the classifier based on ALL training data, and test its prediction on the unseen validation set: \u001b[39;00m\n\u001b[0;32m     51\u001b[0m validaiton_scores,validation_confusion_metrices_per_window,_,trained_clf\u001b[38;5;241m=\u001b[39mrun_windowed_classification_aug(epochs_cropped,train_set_data,train_set_labels,validation_set_data_uncropped,validation_set_labels,params_dict)\n",
      "Cell \u001b[1;32mIn[8], line 190\u001b[0m, in \u001b[0;36mrun_windowed_classification_aug_cv\u001b[1;34m(epochs_cropped, cv_split, train_set_data, train_set_labels, train_set_data_uncroped, params_dict)\u001b[0m\n\u001b[0;32m    188\u001b[0m augmented_x,augmented_y\u001b[38;5;241m=\u001b[39maugment_data(augmentation_params,data_fold_x_train_to_augment,y_train,sfreq)\n\u001b[0;32m    189\u001b[0m \u001b[38;5;66;03m#run classifier on the data fold\u001b[39;00m\n\u001b[1;32m--> 190\u001b[0m curr_scores_windows,confusion_metrices_per_window,_\u001b[38;5;241m=\u001b[39m\u001b[43mrun_windowed_classification_on_fold\u001b[49m\u001b[43m(\u001b[49m\u001b[43maugmented_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43maugmented_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_set_data_uncroped\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mparams_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43mw_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43mw_length\u001b[49m\u001b[43m)\u001b[49m         \n\u001b[0;32m    191\u001b[0m scores_windows\u001b[38;5;241m.\u001b[39mappend(curr_scores_windows)\n\u001b[0;32m    192\u001b[0m folds_confusion_metrices_per_window\u001b[38;5;241m.\u001b[39mappend(confusion_metrices_per_window)\n",
      "Cell \u001b[1;32mIn[8], line 108\u001b[0m, in \u001b[0;36mrun_windowed_classification_on_fold\u001b[1;34m(fold_train_data_x, fold_train_data_y, fold_test_data_x_uncroped, fold_test_data_y, params_dict, w_start, w_length)\u001b[0m\n\u001b[0;32m    103\u001b[0m combined_labels_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmotor_imagery\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m [A, B] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrest\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m fold_train_data_y_labels])\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m#fit the selected classifier: \u001b[39;00m\n\u001b[0;32m    106\u001b[0m \n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# clf.fit(fold_train_data_x, fold_train_data_y_labels)\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfold_train_data_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombined_labels_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;66;03m# running classifier: test classifier on sliding window\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m#get string labels instead of numeric for the test\u001b[39;00m\n\u001b[0;32m    112\u001b[0m fold_test_data_y_labels\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray([triggers_label_dict[cur_y] \u001b[38;5;28;01mfor\u001b[39;00m cur_y \u001b[38;5;129;01min\u001b[39;00m fold_test_data_y])\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\BCIEnvironment\\lib\\site-packages\\sklearn\\pipeline.py:402\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[0;32m    377\u001b[0m \n\u001b[0;32m    378\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    401\u001b[0m fit_params_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_fit_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m--> 402\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_steps)\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\BCIEnvironment\\lib\\site-packages\\sklearn\\pipeline.py:360\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    358\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[0;32m    359\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> 360\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m fit_transform_one_cached(\n\u001b[0;32m    361\u001b[0m     cloned_transformer,\n\u001b[0;32m    362\u001b[0m     X,\n\u001b[0;32m    363\u001b[0m     y,\n\u001b[0;32m    364\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    365\u001b[0m     message_clsname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    366\u001b[0m     message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(step_idx),\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_steps[name],\n\u001b[0;32m    368\u001b[0m )\n\u001b[0;32m    369\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\BCIEnvironment\\lib\\site-packages\\joblib\\memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\BCIEnvironment\\lib\\site-packages\\sklearn\\pipeline.py:894\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m    893\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 894\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit_transform(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    895\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    896\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\BCIEnvironment\\lib\\site-packages\\mne\\decoding\\csp.py:252\u001b[0m, in \u001b[0;36mCSP.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;129m@copy_doc\u001b[39m(TransformerMixin\u001b[38;5;241m.\u001b[39mfit_transform)\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):  \u001b[38;5;66;03m# noqa: D102\u001b[39;00m\n\u001b[1;32m--> 252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit_transform(X, y\u001b[38;5;241m=\u001b[39my, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\BCIEnvironment\\lib\\site-packages\\mne\\decoding\\mixin.py:33\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\BCIEnvironment\\lib\\site-packages\\mne\\decoding\\csp.py:181\u001b[0m, in \u001b[0;36mCSP.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    179\u001b[0m n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_classes)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_classes must be >= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponent_order \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malternate\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    184\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomponent_order=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malternate\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m requires two \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    185\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclasses, but data contains \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m classes; use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    186\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomponent_order=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmutual_info\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_classes)\n\u001b[0;32m    188\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: n_classes must be >= 2."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#this cell, loads roi 3 datafiles (assuming they are last in the recording_files list (if not, change it... maybe explicitly name them))\n",
    "#it then, run the same preprocessing pipelines in his files, and concatinate it into a single \"combined_preprocessing_dict\", from here, everything works with the same functions that run on single participants\n",
    "\n",
    "\n",
    "\n",
    "#define which subject to currently check: \n",
    "for recording_file,Subject in zip(recording_files[9:11],subject_names[9:11]):\n",
    "    print(recording_file,Subject)\n",
    "\n",
    "#this code is custom to aggregate all 3 of roi recordings into a single processing_dict structure. \n",
    "\n",
    "#####################################################\n",
    "#define manually paramaters that we wish to change: \n",
    "#get all possible grid_search combinations: \n",
    "iteration_ind=0 #select some grid search combination - you can manualy change the params after getting the \"params_dict\" below\n",
    "grid_search_dict_copy=grid_search_dict.copy()\n",
    "all_grid_combinations = list(itertools.product(*all_options))\n",
    "#here i can change manually the current iteration params: \n",
    "grid_search_dict_copy['Electorde_Groups_names_grid']=['FC+C+CP']\n",
    "grid_search_dict_copy['filters_bands']=[[[8, 12], [12, 20], [20, 28], [28, 32]]]#[[[8,12], [12, 16],[16,20],[20,24],[24,28],[28,32]]]\n",
    "#this cell allow to test specific iterations\n",
    "params_dict=set_up_params_for_current_grid_iteration(all_grid_combinations,iteration_ind,grid_search_dict_copy)\n",
    "params_dict['subject']=Subject\n",
    "params_dict['recording_file']=recording_file\n",
    "params_dict['filter_method']='iir'\n",
    "params_dict['LowPass']=8\n",
    "params_dict['HighPass']=32\n",
    "params_dict['augmentation_params']={'win_len': 1, 'win_step': 0.1}\n",
    "params_dict['classifier_window_s']=0.5\n",
    "params_dict['classifier_window_e']=4.5\n",
    "params_dict['windowed_prediction_params']={'win_len': 0.5, 'win_step': 0.1}\n",
    "params_dict['pipeline_name']='csp+lda'\n",
    "params_dict['n_components_fbcsp']=4\n",
    "\n",
    "##########################preprocess each of the Frecording seperately#########################\n",
    "preprocessing_dicts=[]\n",
    "#get all 3 of roi files: \n",
    "for recording_file,subject in zip(recording_files[9:12],subject_names[9:12]):\n",
    "    print(recording_file,subject)\n",
    "    params_dict['recording_file']=recording_file\n",
    "    train_inds,validation_inds,preprocessing_dict=run_pre_processing_extract_validation_set(recording_path,current_path,params_dict)\n",
    "    preprocessing_dicts.append(preprocessing_dict)\n",
    "##############################################################################################\n",
    "\n",
    "#combine all preprocessing structures: \n",
    "#combine each file preprocessing_dict into a single dictionary:\n",
    "#take the first roi file and modify its triggers to be consistent with the later two: \n",
    "\n",
    "combined_preprocessing_dict=copy.deepcopy(preprocessing_dicts[0]) #the deep copy is important here as we have a dictionary that contains lists/dictionaries\n",
    "\n",
    "#change the epochs structures triggers information to be consistent with the next 2 files: (roi first file had triggers of 2,5 and 6) \n",
    "#combined_preprocessing_dict['epochs'].event_id={'left': 3, 'rest': 6, 'right': 7} #change the event ids to be the same as his other 2 files\n",
    "#combined_preprocessing_dict['epochs'].events[:,2]=combined_preprocessing_dict['epochs'].events[:,2]+1 #change the event numeric data within the epoch structure\n",
    "#for fb_num in range(len(combined_preprocessing_dict['filter_bank_epochs'])): #do the same on the filter bank epochs (should be able to handle arbitraty number of bands)\n",
    "#    combined_preprocessing_dict['filter_bank_epochs'][fb_num].events[:,2]=combined_preprocessing_dict['filter_bank_epochs'][fb_num].events[:,2]+1\n",
    "#    combined_preprocessing_dict['filter_bank_epochs'][fb_num].event_id={'left': 3, 'rest': 6, 'right': 7}\n",
    "\n",
    "#now that the first recording file is set as standard - read the other two files and add their information to the combined dictionary: \n",
    "add_to_inds=combined_preprocessing_dict['epochs'].events.shape[0] \n",
    "for i,cur_preprocessing_dict in enumerate(preprocessing_dicts[1:]): \n",
    "    #aggregate all training_indexes: \n",
    "    combined_preprocessing_dict['train_inds'] = np.concatenate([combined_preprocessing_dict['train_inds'],cur_preprocessing_dict['train_inds']+add_to_inds])\n",
    "    #aggregate all validation indexes\n",
    "    validation_inds_df=cur_preprocessing_dict['validation_inds']\n",
    "    validation_inds_df.index=validation_inds_df.index+add_to_inds\n",
    "    validation_inds_df['original_trial_ind']=validation_inds_df['original_trial_ind']+add_to_inds\n",
    "    combined_preprocessing_dict['validation_inds'] = pd.concat([combined_preprocessing_dict['validation_inds'],validation_inds_df],axis=0)\n",
    "    #increase the number to add to keep indexes consistent (i.e. first was 0-60, next file should have them at the range of 60-120 and so on)\n",
    "    add_to_inds+=cur_preprocessing_dict['epochs'].events.shape[0] #this should allow for files with different number of epochs. \n",
    "\n",
    "    for fb_filter_num in range(len(combined_preprocessing_dict['filter_bank_epochs'])):\n",
    "        combined_preprocessing_dict['filter_bank_epochs'][fb_filter_num]=mne.concatenate_epochs([combined_preprocessing_dict['filter_bank_epochs'][fb_filter_num],cur_preprocessing_dict['filter_bank_epochs'][fb_filter_num]], on_mismatch='warn' , verbose=None)\n",
    "    combined_preprocessing_dict['epochs']=mne.concatenate_epochs([combined_preprocessing_dict['epochs'],cur_preprocessing_dict['epochs']], on_mismatch='warn' , verbose=None)\n",
    "    \n",
    "combined_preprocessing_dict['events_triggers_dict']=preprocessing_dict['events_triggers_dict']\n",
    "params_dict['preprocessing_dict']=preprocessing_dict\n",
    "\n",
    "\n",
    "#test it: \n",
    "fig,w_times,scores_windows,folds_confusion_metrices_per_window,validation_scores,validation_confusion_metrices_per_window,trained_clf=run_training_and_classification_on_selected_params(params_dict,combined_preprocessing_dict,to_plot=True,figure_outputs_path=figure_outputs_path,fig_name='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load an unseen data recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gilad_ses-1_task-mi_run-004_eeg.xdf'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording_files[3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NH_Block_3.xdf'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording_files[311]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=67, n_times=307260\n",
      "    Range : 0 ... 307259 =      0.000 ...   614.518 secs\n",
      "Ready.\n",
      "\n",
      "###########################################################\n",
      "removing subject sepecific bad electrodes from the raw data\n",
      "\n",
      "###########################################################\n",
      "removing bad channels from epochs:\n",
      "\n",
      "###########################################################\n",
      "running csd\n",
      "Fitted sphere radius:         95.0 mm\n",
      "Origin head coordinates:      0.0 -0.0 0.0 mm\n",
      "Origin device coordinates:    0.0 -0.0 0.0 mm\n",
      "\n",
      "###########################################################\n",
      "filtering the data\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 8 - 32 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 8.00, 32.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 8 - 12 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 8.00, 12.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 12 - 20 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 12.00, 20.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 20 - 28 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 20.00, 28.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 28 - 32 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 28.00, 32.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Used Annotations descriptions: ['Beep', 'Experiment Ended', 'Left', 'Long Break', 'Rest', 'Resting', 'Right']\n",
      "\n",
      "###########################################################\n",
      "extracting event info: {'Beep': 1, 'Experiment Ended': 2, 'Left': 3, 'Long Break': 4, 'Rest': 5, 'Resting': 6, 'Right': 7}\n",
      "\n",
      "###########################################################\n",
      "Not setting metadata\n",
      "60 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 60 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "60 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 60 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "60 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 60 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "60 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 60 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "epoching + selecting current electodes set for analysis:\n",
      "['C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6']\n",
      "Not setting metadata\n",
      "60 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 60 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "\n",
      "###########################################################\n",
      "removing bad channels from epochs:\n",
      "\n",
      "###########################################################\n",
      "the current selected electrodes: {'C2', 'C5', 'C4', 'Cz', 'C3', 'C6', 'C1'} allready exclude the requested electrodes to remove {'TP10', 'FT9', 'TP9', 'FT10'}\n",
      "#############################################################\n",
      "putting aside 20% of the data: trial numbers are:\n",
      " [48 56  2 27  9 21 30 39  0 41 25 24]\n",
      "\n",
      "remaining 80% of the trials go into training for cv:\n",
      " [17 53 29 59 49 50  5 13 47  3 31 20 43 14  4 35 11 55 28 23 22 38 19  8\n",
      " 57  6 33 34 15 16 44 42 45 52 26 12 36 32 46 18 54 10 40  7 51 58  1 37]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params_dict['recording_file']=recording_files[3]\n",
    "train_inds,validation_inds,preprocessing_dict=run_pre_processing_extract_validation_set(recording_path,current_path,params_dict)\n",
    "params_dict['events_triggers_dict']=preprocessing_dict['events_triggers_dict']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chosen window prediction range is [3, 4]\n",
      "note that the prediction paramaters (that the classifier is trained on) are: {'win_len': 0.5, 'win_step': 0.1}\n",
      "consider if you want the preciction range to match the prediction_param\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[117], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#plot the precision recall curve, and extract the relevant decision information into a dataframe\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m return_df\u001b[38;5;241m=\u001b[39m\u001b[43mplot_precision_recall_curves_from_trained_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocessing_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43mparams_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43mprecision_recall_curve_timerange\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrained_clf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrained_clf\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpredict_validation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m display(return_df)\n\u001b[0;32m      6\u001b[0m data_to_predict\u001b[38;5;241m=\u001b[39mpreprocessing_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy()\u001b[38;5;241m.\u001b[39mcrop(tmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,tmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.5\u001b[39m)\u001b[38;5;241m.\u001b[39mget_data()[:,:]\n",
      "Cell \u001b[1;32mIn[11], line 54\u001b[0m, in \u001b[0;36mplot_precision_recall_curves_from_trained_classifier\u001b[1;34m(preprocessing_dict, params_dict, precision_recall_curve_timerange, trained_clf, predict_validation)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_classes):\n\u001b[1;32m---> 54\u001b[0m         precision[i], recall[i], thresholds[i] \u001b[38;5;241m=\u001b[39m precision_recall_curve(Y[:, i], \u001b[43my_score\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     55\u001b[0m         average_precision[i] \u001b[38;5;241m=\u001b[39m average_precision_score(Y[:, i], y_score[:, i])\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# A \"micro-average\": quantifying score on all classes jointly\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "#plot the precision recall curve, and extract the relevant decision information into a dataframe\n",
    "\n",
    "return_df=plot_precision_recall_curves_from_trained_classifier(preprocessing_dict,params_dict,precision_recall_curve_timerange=[3,4],trained_clf=trained_clf,predict_validation=False)\n",
    "display(return_df)\n",
    "\n",
    "data_to_predict=preprocessing_dict['epochs'].copy().crop(tmin=1,tmax=1.5).get_data()[:,:]\n",
    "thresholded_prediction=trained_clf.decision_function(data_to_predict)\n",
    "\n",
    "#note that here you can decide on which thresholds to use to better optimize your \"real\" usecase\n",
    "thresholded_prediction\n",
    "#prediction=trained_clf.predict(data_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_inds': array([17, 53, 29, 59, 49, 50,  5, 13, 47,  3, 31, 20, 43, 14,  4, 35, 11,\n",
       "        55, 28, 23, 22, 38, 19,  8, 57,  6, 33, 34, 15, 16, 44, 42, 45, 52,\n",
       "        26, 12, 36, 32, 46, 18, 54, 10, 40,  7, 51, 58,  1, 37],\n",
       "       dtype=int64),\n",
       " 'validation_inds':     label  original_trial_ind\n",
       " 48      3                  48\n",
       " 56      7                  56\n",
       " 2       6                   2\n",
       " 27      6                  27\n",
       " 9       7                   9\n",
       " 21      3                  21\n",
       " 30      7                  30\n",
       " 39      3                  39\n",
       " 0       6                   0\n",
       " 41      6                  41\n",
       " 25      7                  25\n",
       " 24      3                  24,\n",
       " 'epochs': <Epochs |  60 events (all good), -3 – 4 s, baseline off, ~11.3 MB, data loaded,\n",
       "  'Left': 20\n",
       "  'Resting': 20\n",
       "  'Right': 20>,\n",
       " 'filter_bank_epochs': [<Epochs |  60 events (all good), -3 – 4 s, baseline off, ~11.3 MB, data loaded,\n",
       "   'Left': 20\n",
       "   'Resting': 20\n",
       "   'Right': 20>,\n",
       "  <Epochs |  60 events (all good), -3 – 4 s, baseline off, ~11.3 MB, data loaded,\n",
       "   'Left': 20\n",
       "   'Resting': 20\n",
       "   'Right': 20>,\n",
       "  <Epochs |  60 events (all good), -3 – 4 s, baseline off, ~11.3 MB, data loaded,\n",
       "   'Left': 20\n",
       "   'Resting': 20\n",
       "   'Right': 20>,\n",
       "  <Epochs |  60 events (all good), -3 – 4 s, baseline off, ~11.3 MB, data loaded,\n",
       "   'Left': 20\n",
       "   'Resting': 20\n",
       "   'Right': 20>],\n",
       " 'events_triggers_dict': {'Left': 3, 'Resting': 6, 'Right': 7}}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LowPass': 8,\n",
       " 'HighPass': 28,\n",
       " 'PerformCsd': True,\n",
       " 'filter_method': 'iir',\n",
       " 'n_components': 4,\n",
       " 'n_components_fbcsp': 4,\n",
       " 'filters_bands': [[8, 12], [12, 20], [20, 28], [28, 32]],\n",
       " 'Electorde_Group': ['FC5',\n",
       "  'FC3',\n",
       "  'FC1',\n",
       "  'FC2',\n",
       "  'FC4',\n",
       "  'FC6',\n",
       "  'FT7',\n",
       "  'FT8',\n",
       "  'C5',\n",
       "  'C3',\n",
       "  'C1',\n",
       "  'Cz',\n",
       "  'C2',\n",
       "  'C4',\n",
       "  'C6',\n",
       "  'CP5',\n",
       "  'CP3',\n",
       "  'CP1',\n",
       "  'CPz',\n",
       "  'CP2',\n",
       "  'CP4',\n",
       "  'CP6'],\n",
       " 'Electorde_Group_name': 'FC+C+CP',\n",
       " 'epoch_tmin': -3,\n",
       " 'epoch_tmax': 4,\n",
       " 'classifier_window_s': 0.5,\n",
       " 'classifier_window_e': 4.5,\n",
       " 'augmentation_params': {'win_len': 1, 'win_step': 0.1},\n",
       " 'windowed_prediction_params': {'win_len': 0.5, 'win_step': 0.1},\n",
       " 'pipeline_name': 'csp+lda',\n",
       " 'subject': 'Gilad',\n",
       " 'recording_file': 'Gilad_ses-1_task-mi_run-004_eeg.xdf',\n",
       " 'preprocessing_dict': {'train_inds': array([28, 38, 21, 33, 13, 19, 30, 15, 25, 22,  9, 24, 23,  1,  3, 32, 10,\n",
       "         11,  6, 37, 14,  8, 34,  7, 12, 16, 39,  4,  5, 29, 27, 35],\n",
       "        dtype=int64),\n",
       "  'validation_inds':      label  original_trial_ind\n",
       "  100      3                 100\n",
       "  111      3                 111\n",
       "  116      7                 116\n",
       "  97       7                  97\n",
       "  98       3                  98\n",
       "  82       7                  82\n",
       "  106      3                 106\n",
       "  80       7                  80,\n",
       "  'epochs': <Epochs |  40 events (all good), -3 – 4 s, baseline off, ~23.6 MB, data loaded,\n",
       "   'Left': 20\n",
       "   'Right': 20>,\n",
       "  'filter_bank_epochs': [<Epochs |  40 events (all good), -3 – 4 s, baseline off, ~23.6 MB, data loaded,\n",
       "    'Left': 20\n",
       "    'Right': 20>,\n",
       "   <Epochs |  40 events (all good), -3 – 4 s, baseline off, ~23.6 MB, data loaded,\n",
       "    'Left': 20\n",
       "    'Right': 20>,\n",
       "   <Epochs |  40 events (all good), -3 – 4 s, baseline off, ~23.6 MB, data loaded,\n",
       "    'Left': 20\n",
       "    'Right': 20>,\n",
       "   <Epochs |  40 events (all good), -3 – 4 s, baseline off, ~23.6 MB, data loaded,\n",
       "    'Left': 20\n",
       "    'Right': 20>],\n",
       "  'events_triggers_dict': {'Left': 3, 'Right': 7}}}"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_predict=preprocessing_dict['epochs'].copy().crop(tmin=0,tmax=4).get_data()[:,:]\n",
    "thresholded_prediction=trained_clf.decision_function(data_to_predict)\n",
    "\n",
    "#note that here you can decide on which thresholds to use to better optimize your \"real\" usecase\n",
    "thresholded_prediction\n",
    "prediction=trained_clf.decision_function(data_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 7, 6, 7, 3, 6, 6, 7, 6, 7, 3, 6, 6, 3, 6, 3, 3, 7, 3, 6, 6, 3,\n",
       "       7, 6, 3, 7, 7, 6, 6, 3, 7, 7, 6, 6, 7, 6, 6, 7, 3, 3, 7, 6, 6, 3,\n",
       "       3, 7, 7, 3, 3, 7, 3, 6, 3, 7, 3, 3, 7, 7, 3, 7])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing_dict['epochs'].events[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.05743089, -0.12092408, -2.02054044,  2.34173342, -2.80396141,\n",
       "       -1.74096676, -3.37111042,  2.07014942, -2.31855942,  0.63621711,\n",
       "       -1.72595665, -2.78840953,  1.38342753, -2.32474348, -3.75611439,\n",
       "       -0.9167688 , -2.72777547,  2.80184057, -1.76689824,  0.66274782,\n",
       "        0.50811884, -0.59933874,  2.16820401, -1.14912679, -3.7033061 ,\n",
       "        1.63791111,  3.96670447, -0.05941875, -0.68133579, -2.86327701,\n",
       "        3.62487583,  2.1970543 ,  1.71086867, -1.58216642,  2.51537739,\n",
       "       -0.81337713, -2.22370315,  1.92836754, -4.69445101, -4.20238705,\n",
       "        2.13025862,  0.79870441,  1.52976375, -1.86972182, -3.09414998,\n",
       "        2.20597322,  0.70358176, -2.78933119, -2.00992266, -1.4253118 ,\n",
       "       -1.57629581, -2.19308317, -0.03776897,  2.32050127, -1.74396613,\n",
       "       -2.62600119,  4.04140005,  1.20334074, -3.72767294,  0.38627685])"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict['preprocessing_dict']['events_triggers_dict']=preprocessing_dict['events_triggers_dict']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_step = params_dict['windowed_prediction_params'].get('win_step')\n",
    "win_len = params_dict['windowed_prediction_params'].get('win_len')\n",
    "sfreq=preprocessing_dict['epochs'].info['sfreq']\n",
    "w_length = int(sfreq * win_len) \n",
    "w_step = int(sfreq * win_step)\n",
    "w_start = np.arange(0, (preprocessing_dict['epochs'].get_data()[:].shape[2]) - w_length, w_step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 22, 3501)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing_dict['epochs'].get_data().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "    epochs_copy=preprocessing_dict['epochs']\n",
    "    train_inds=preprocessing_dict['train_inds']\n",
    "    validation_inds=preprocessing_dict['validation_inds']['original_trial_ind'].values\n",
    "\n",
    "    #crop the data according to the training window: \n",
    "    returned_dict=crop_the_data(epochs_copy,train_inds,validation_inds,params_dict['classifier_window_s'],params_dict['classifier_window_e']) #two more paramters here are tmin and tmax which are not used apparently. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_data=returned_dict['train_set_data_uncroped']\n",
    "train_set_labels = preprocessing_dict['epochs'].events[:,2]\n",
    "##train_set_labels=returned_dict['train_set_labels_uncroped']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "triggers_label_dict={val:key for key,val in params_dict['preprocessing_dict']['events_triggers_dict'].items()} \n",
    "test_data_y_labels=np.array([triggers_label_dict[cur_y] for cur_y in train_set_labels])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Rest', 'Rest', 'Right', 'Rest', 'Rest', 'Right', 'Rest', 'Left',\n",
       "       'Rest', 'Rest', 'Rest', 'Right', 'Rest', 'Rest', 'Right', 'Rest',\n",
       "       'Left', 'Rest', 'Rest', 'Rest', 'Left', 'Rest', 'Rest', 'Left',\n",
       "       'Rest', 'Left', 'Rest', 'Right', 'Rest', 'Left', 'Rest', 'Rest',\n",
       "       'Rest', 'Left', 'Rest', 'Right', 'Rest', 'Rest', 'Left', 'Rest',\n",
       "       'Right', 'Rest', 'Right', 'Rest', 'Rest', 'Rest', 'Left', 'Rest',\n",
       "       'Right', 'Rest', 'Right', 'Rest', 'Rest', 'Rest', 'Right', 'Rest',\n",
       "       'Rest', 'Rest', 'Right', 'Rest', 'Left', 'Rest', 'Left', 'Rest',\n",
       "       'Right', 'Rest', 'Rest', 'Rest', 'Left', 'Rest', 'Left', 'Rest',\n",
       "       'Right', 'Rest', 'Right', 'Rest', 'Left', 'Rest', 'Left', 'Rest',\n",
       "       'Right', 'Rest', 'Left', 'Rest', 'Rest', 'Left', 'Rest', 'Right',\n",
       "       'Rest', 'Left', 'Rest', 'Left', 'Rest', 'Right', 'Rest', 'Right',\n",
       "       'Rest', 'Left', 'Rest', 'Right'], dtype='<U5')"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [60, 48]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[249], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mrun_windowed_pretrained_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrained_clf\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_set_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_data_y_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43mw_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43mw_length\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[75], line 107\u001b[0m, in \u001b[0;36mrun_windowed_pretrained_classifier\u001b[1;34m(clf, x_uncropped, y, w_start, w_length)\u001b[0m\n\u001b[0;32m    105\u001b[0m fold_data\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39msqueeze(x_uncropped[:, :, n:(n \u001b[38;5;241m+\u001b[39m w_length),:]) \u001b[38;5;66;03m#using squeeze here so that if the 4th dimention size is 1 it will reduce it to a 3d vector\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m#if the classifier uses a filterbank its input should be 4d (trials,channels,timesteps,filter_bands) and if it doesnt its 3d (trials,channels,timesteps)\u001b[39;00m\n\u001b[1;32m--> 107\u001b[0m fold_score_on_time_window\u001b[38;5;241m=\u001b[39m\u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfold_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m#append the score for the LDA, using this csp to predict the relevant test scores: \u001b[39;00m\n\u001b[0;32m    109\u001b[0m scores_per_time_window\u001b[38;5;241m.\u001b[39mappend(fold_score_on_time_window)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\BCIEnvironment\\lib\\site-packages\\sklearn\\pipeline.py:723\u001b[0m, in \u001b[0;36mPipeline.score\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    722\u001b[0m     score_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sample_weight\n\u001b[1;32m--> 723\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mscore(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscore_params)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\BCIEnvironment\\lib\\site-packages\\sklearn\\base.py:638\u001b[0m, in \u001b[0;36mClassifierMixin.score\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    614\u001b[0m \u001b[38;5;124;03mReturn the mean accuracy on the given test data and labels.\u001b[39;00m\n\u001b[0;32m    615\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;124;03m    Mean accuracy of ``self.predict(X)`` wrt. `y`.\u001b[39;00m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    636\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[1;32m--> 638\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\BCIEnvironment\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:192\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m validate_parameter_constraints(\n\u001b[0;32m    188\u001b[0m     parameter_constraints, params, caller_name\u001b[38;5;241m=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\n\u001b[0;32m    189\u001b[0m )\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    198\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    200\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    202\u001b[0m     )\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\BCIEnvironment\\lib\\site-packages\\sklearn\\metrics\\_classification.py:221\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 221\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    222\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\BCIEnvironment\\lib\\site-packages\\sklearn\\metrics\\_classification.py:86\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[0;32m     60\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \n\u001b[0;32m     62\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     88\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\BCIEnvironment\\lib\\site-packages\\sklearn\\utils\\validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    395\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    400\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [60, 48]"
     ]
    }
   ],
   "source": [
    "run_windowed_pretrained_classifier(trained_clf,train_set_data,test_data_y_labels,w_start,w_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.26666666666666666,\n",
       "  0.26666666666666666,\n",
       "  0.2833333333333333,\n",
       "  0.26666666666666666,\n",
       "  0.3333333333333333,\n",
       "  0.35,\n",
       "  0.3333333333333333,\n",
       "  0.31666666666666665,\n",
       "  0.31666666666666665,\n",
       "  0.3333333333333333,\n",
       "  0.3333333333333333,\n",
       "  0.31666666666666665,\n",
       "  0.36666666666666664,\n",
       "  0.36666666666666664,\n",
       "  0.35,\n",
       "  0.38333333333333336,\n",
       "  0.38333333333333336,\n",
       "  0.4166666666666667,\n",
       "  0.4,\n",
       "  0.4166666666666667,\n",
       "  0.4166666666666667,\n",
       "  0.38333333333333336,\n",
       "  0.36666666666666664,\n",
       "  0.4,\n",
       "  0.43333333333333335,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5333333333333333,\n",
       "  0.5333333333333333,\n",
       "  0.5333333333333333,\n",
       "  0.5166666666666667,\n",
       "  0.5333333333333333,\n",
       "  0.5666666666666667,\n",
       "  0.5166666666666667,\n",
       "  0.5,\n",
       "  0.55,\n",
       "  0.5333333333333333,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.4666666666666667,\n",
       "  0.5,\n",
       "  0.4666666666666667,\n",
       "  0.5,\n",
       "  0.5333333333333333,\n",
       "  0.5333333333333333,\n",
       "  0.5666666666666667,\n",
       "  0.55,\n",
       "  0.5666666666666667,\n",
       "  0.5666666666666667,\n",
       "  0.55,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.48333333333333334,\n",
       "  0.4166666666666667,\n",
       "  0.4,\n",
       "  0.4166666666666667,\n",
       "  0.43333333333333335,\n",
       "  0.43333333333333335,\n",
       "  0.5166666666666667,\n",
       "  0.5166666666666667,\n",
       "  0.4,\n",
       "  0.45,\n",
       "  0.4166666666666667,\n",
       "  0.5166666666666667,\n",
       "  0.5333333333333333,\n",
       "  0.55],\n",
       " [array([[13,  7],\n",
       "         [17,  3]], dtype=int64),\n",
       "  array([[13,  7],\n",
       "         [17,  3]], dtype=int64),\n",
       "  array([[13,  7],\n",
       "         [16,  4]], dtype=int64),\n",
       "  array([[12,  8],\n",
       "         [16,  4]], dtype=int64),\n",
       "  array([[14,  6],\n",
       "         [14,  6]], dtype=int64),\n",
       "  array([[12,  8],\n",
       "         [11,  9]], dtype=int64),\n",
       "  array([[13,  7],\n",
       "         [13,  7]], dtype=int64),\n",
       "  array([[12,  8],\n",
       "         [13,  7]], dtype=int64),\n",
       "  array([[11,  9],\n",
       "         [12,  8]], dtype=int64),\n",
       "  array([[12,  8],\n",
       "         [12,  8]], dtype=int64),\n",
       "  array([[11,  9],\n",
       "         [11,  9]], dtype=int64),\n",
       "  array([[10, 10],\n",
       "         [11,  9]], dtype=int64),\n",
       "  array([[10, 10],\n",
       "         [ 8, 12]], dtype=int64),\n",
       "  array([[12,  8],\n",
       "         [10, 10]], dtype=int64),\n",
       "  array([[10, 10],\n",
       "         [ 9, 11]], dtype=int64),\n",
       "  array([[11,  9],\n",
       "         [ 8, 12]], dtype=int64),\n",
       "  array([[11,  9],\n",
       "         [ 8, 12]], dtype=int64),\n",
       "  array([[11,  9],\n",
       "         [ 6, 14]], dtype=int64),\n",
       "  array([[11,  9],\n",
       "         [ 7, 13]], dtype=int64),\n",
       "  array([[11,  9],\n",
       "         [ 6, 14]], dtype=int64),\n",
       "  array([[10, 10],\n",
       "         [ 5, 15]], dtype=int64),\n",
       "  array([[10, 10],\n",
       "         [ 7, 13]], dtype=int64),\n",
       "  array([[ 9, 11],\n",
       "         [ 7, 13]], dtype=int64),\n",
       "  array([[ 9, 11],\n",
       "         [ 5, 15]], dtype=int64),\n",
       "  array([[10, 10],\n",
       "         [ 4, 16]], dtype=int64),\n",
       "  array([[13,  7],\n",
       "         [ 3, 17]], dtype=int64),\n",
       "  array([[12,  8],\n",
       "         [ 2, 18]], dtype=int64),\n",
       "  array([[14,  6],\n",
       "         [ 2, 18]], dtype=int64),\n",
       "  array([[14,  6],\n",
       "         [ 2, 18]], dtype=int64),\n",
       "  array([[14,  6],\n",
       "         [ 2, 18]], dtype=int64),\n",
       "  array([[13,  7],\n",
       "         [ 2, 18]], dtype=int64),\n",
       "  array([[15,  5],\n",
       "         [ 3, 17]], dtype=int64),\n",
       "  array([[16,  4],\n",
       "         [ 2, 18]], dtype=int64),\n",
       "  array([[15,  5],\n",
       "         [ 4, 16]], dtype=int64),\n",
       "  array([[14,  6],\n",
       "         [ 4, 16]], dtype=int64),\n",
       "  array([[17,  3],\n",
       "         [ 4, 16]], dtype=int64),\n",
       "  array([[17,  3],\n",
       "         [ 5, 15]], dtype=int64),\n",
       "  array([[15,  5],\n",
       "         [ 5, 15]], dtype=int64),\n",
       "  array([[15,  5],\n",
       "         [ 5, 15]], dtype=int64),\n",
       "  array([[16,  4],\n",
       "         [ 8, 12]], dtype=int64),\n",
       "  array([[17,  3],\n",
       "         [ 7, 13]], dtype=int64),\n",
       "  array([[15,  5],\n",
       "         [ 7, 13]], dtype=int64),\n",
       "  array([[16,  4],\n",
       "         [ 6, 14]], dtype=int64),\n",
       "  array([[18,  2],\n",
       "         [ 6, 14]], dtype=int64),\n",
       "  array([[18,  2],\n",
       "         [ 6, 14]], dtype=int64),\n",
       "  array([[18,  2],\n",
       "         [ 4, 16]], dtype=int64),\n",
       "  array([[18,  2],\n",
       "         [ 5, 15]], dtype=int64),\n",
       "  array([[19,  1],\n",
       "         [ 5, 15]], dtype=int64),\n",
       "  array([[18,  2],\n",
       "         [ 4, 16]], dtype=int64),\n",
       "  array([[16,  4],\n",
       "         [ 3, 17]], dtype=int64),\n",
       "  array([[14,  6],\n",
       "         [ 4, 16]], dtype=int64),\n",
       "  array([[13,  7],\n",
       "         [ 3, 17]], dtype=int64),\n",
       "  array([[14,  6],\n",
       "         [ 5, 15]], dtype=int64),\n",
       "  array([[10, 10],\n",
       "         [ 5, 15]], dtype=int64),\n",
       "  array([[10, 10],\n",
       "         [ 6, 14]], dtype=int64),\n",
       "  array([[11,  9],\n",
       "         [ 6, 14]], dtype=int64),\n",
       "  array([[12,  8],\n",
       "         [ 6, 14]], dtype=int64),\n",
       "  array([[13,  7],\n",
       "         [ 7, 13]], dtype=int64),\n",
       "  array([[16,  4],\n",
       "         [ 5, 15]], dtype=int64),\n",
       "  array([[16,  4],\n",
       "         [ 5, 15]], dtype=int64),\n",
       "  array([[13,  7],\n",
       "         [ 9, 11]], dtype=int64),\n",
       "  array([[15,  5],\n",
       "         [ 8, 12]], dtype=int64),\n",
       "  array([[15,  5],\n",
       "         [10, 10]], dtype=int64),\n",
       "  array([[17,  3],\n",
       "         [ 6, 14]], dtype=int64),\n",
       "  array([[17,  3],\n",
       "         [ 5, 15]], dtype=int64),\n",
       "  array([[18,  2],\n",
       "         [ 5, 15]], dtype=int64)])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_windowed_pretrained_classifier(trained_clf,preprocessing_dict['epochs'].get_data()[:],test_data_y_labels,w_start,w_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1,  5,  6, 13, 14, 16, 19, 23, 24, 27, 34, 35, 37, 38, 39, 40, 42,\n",
       "        48, 55, 59], dtype=int64),\n",
       " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "       dtype=int64))"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(preprocessing_dict['epochs'].events == 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  3  4  7 10 11 12 15 18 20 25 26 29 33 36 41 46 54 56 57]\n"
     ]
    }
   ],
   "source": [
    "print(np.where(preprocessing_dict['epochs'].events[:,2] == 7)[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine for specific trials performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 6 3 7 7 6 6 7 3 3 7 7 7 6 6 7 6 3 7 6 7 3 3 6 6 7 7 6 3 7 3 3 3 7 6 6 7\n",
      " 6 6 6 6 7 6 3 3 3 7 3 6 3 3 3 3 3 7 6 7 7 3 6]\n"
     ]
    }
   ],
   "source": [
    "print(preprocessing_dict['epochs'].events[:,2] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Right'"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_clf.predict(data_to_predict[0:1,:,:])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_array = []\n",
    "\n",
    "# Define the start, end, and step size\n",
    "time_start = 0\n",
    "time_end = 3.5\n",
    "time_step = 0.1\n",
    "\n",
    "# Calculate the number of steps based on the start, end, and step size\n",
    "num_steps = int((time_end - time_start) / time_step)\n",
    "for i in range(num_steps):\n",
    "    tmin = time_start + i * time_step\n",
    "    data_to_predict=preprocessing_dict['epochs'].copy().crop(tmin,tmax=(tmin+0.5)).get_data()[:,:]\n",
    "    prediction=trained_clf.predict_log_proba(data_to_predict)\n",
    "    prediction_array.append(prediction)\n",
    "prediction_array = np.array(prediction_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02571878, -3.84543385, -5.5180298 ],\n",
       "       [-0.04796107, -3.15042372, -5.52267848],\n",
       "       [-0.14237432, -2.33515466, -3.32679693],\n",
       "       [-0.28458332, -1.9796564 , -2.21132269],\n",
       "       [-0.85311045, -1.23206958, -1.26505358],\n",
       "       [-0.98020377, -1.37938221, -0.98609282],\n",
       "       [-1.85896112, -2.54337287, -0.26714152],\n",
       "       [-0.94491085, -2.77127357, -0.60019701],\n",
       "       [-2.64941553, -3.43224664, -0.10870697],\n",
       "       [-2.16702087, -3.48202433, -0.15696191],\n",
       "       [-3.40779699, -4.34973405, -0.0471171 ],\n",
       "       [-2.44922483, -3.56042853, -0.12192715],\n",
       "       [-3.86833055, -4.30116157, -0.03505328],\n",
       "       [-2.68136814, -3.92536107, -0.09233946],\n",
       "       [-0.93810394, -2.61249191, -0.62496666],\n",
       "       [-0.63401851, -1.65674042, -1.27731669],\n",
       "       [-1.57315048, -1.6978606 , -0.49505981],\n",
       "       [-1.016811  , -1.10604178, -1.17964685],\n",
       "       [-0.78526441, -0.89577411, -1.99723893],\n",
       "       [-0.93043313, -1.30022137, -1.09917542],\n",
       "       [-1.62569162, -2.32324622, -0.34917545],\n",
       "       [-0.57488228, -2.58293967, -1.01700289],\n",
       "       [-0.27242821, -2.76557753, -1.73993297],\n",
       "       [-0.46079776, -2.92671381, -1.15313089],\n",
       "       [-0.24759897, -2.81357893, -1.83673294],\n",
       "       [-0.0564784 , -3.22221978, -4.19660104],\n",
       "       [-0.04184964, -3.33898443, -5.2006333 ],\n",
       "       [-0.0710119 , -2.79935074, -4.86658254],\n",
       "       [-0.28761733, -1.43760008, -4.38568181],\n",
       "       [-0.21825263, -1.66104456, -5.09338527],\n",
       "       [-0.10720328, -2.36246771, -4.89693424],\n",
       "       [-0.10007623, -2.43244061, -4.90501577],\n",
       "       [-0.04363571, -3.20117903, -6.22304288],\n",
       "       [-0.02262026, -3.84055058, -7.03040792],\n",
       "       [-0.10313822, -2.39399374, -5.00069821]])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_array[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.39904242e-01, -1.25865222e+00, -5.49070625e+00],\n",
       "       [-2.31116058e-01, -1.60808933e+00, -5.10229834e+00],\n",
       "       [-1.77759797e+00, -3.66563651e+00, -2.16455451e-01],\n",
       "       [-5.96135327e+00, -4.85546266e+00, -1.04162143e-02],\n",
       "       [-4.74792897e-01, -1.19966687e+00, -2.56796348e+00],\n",
       "       [-4.20157101e+00, -2.12245073e+00, -1.44690407e-01],\n",
       "       [-4.13443842e+00, -4.84231195e-02, -3.46548753e+00],\n",
       "       [-9.03727220e+00, -4.89617968e+00, -7.62296163e-03],\n",
       "       [-3.14898067e+00, -8.15955831e-02, -3.33936243e+00],\n",
       "       [-1.30592014e+00, -7.24640590e-01, -1.40822021e+00],\n",
       "       [-5.65640061e-02, -3.79470156e+00, -3.42638021e+00],\n",
       "       [-4.73560895e-01, -1.83998403e+00, -1.52142988e+00],\n",
       "       [-2.07809133e+00, -4.53167715e+00, -1.46103232e-01],\n",
       "       [-6.27487536e-01, -9.06282695e-01, -2.77989398e+00],\n",
       "       [-8.28296008e-01, -5.76677500e-01, -6.53941577e+00],\n",
       "       [-2.76497026e-01, -1.70940357e+00, -2.80361838e+00],\n",
       "       [-9.37520093e-01, -1.99479359e+00, -7.50012792e-01],\n",
       "       [-7.57672164e+00, -3.33015366e+00, -3.69750735e-02],\n",
       "       [-6.75368331e-01, -7.25073753e-01, -4.99936405e+00],\n",
       "       [-2.03258174e+00, -1.31129916e+00, -5.11603639e-01],\n",
       "       [-9.78964095e-01, -5.85128426e-01, -2.69910641e+00],\n",
       "       [-3.10224507e+00, -3.40753002e+00, -8.12871623e-02],\n",
       "       [-3.10347675e+00, -1.56580141e-01, -2.30214358e+00],\n",
       "       [-2.70590609e+00, -7.03074938e-02, -6.82794584e+00],\n",
       "       [-1.73700237e-01, -1.84545179e+00, -6.50413704e+00],\n",
       "       [-3.15296934e+00, -2.00290872e+00, -1.95610192e-01],\n",
       "       [-7.73925725e+00, -7.22165877e+00, -1.16666466e-03],\n",
       "       [-3.43889027e+00, -1.14650547e-01, -2.57410484e+00],\n",
       "       [-3.74379288e+00, -5.10890599e-01, -9.77169807e-01],\n",
       "       [-3.14542184e-01, -3.19528660e+00, -1.47437327e+00],\n",
       "       [-1.15280135e+00, -2.14005737e+00, -5.68100091e-01],\n",
       "       [-2.40931625e+00, -3.62581638e+00, -1.23868602e-01],\n",
       "       [-6.68447453e-01, -2.20557645e+00, -9.74689834e-01],\n",
       "       [-2.65558690e+00, -1.12920776e-01, -3.30986823e+00],\n",
       "       [-8.46520545e-01, -1.06099252e+00, -1.49172959e+00],\n",
       "       [-4.92550971e+00, -2.35404934e-01, -1.59706384e+00],\n",
       "       [-1.47537967e+00, -4.94345400e-01, -1.82425340e+00],\n",
       "       [-8.20298701e-01, -1.76304269e+00, -9.46292047e-01],\n",
       "       [-3.70585930e-01, -1.39819759e+00, -2.77053582e+00],\n",
       "       [-1.52784528e-02, -4.21111102e+00, -8.00903177e+00],\n",
       "       [-4.17428232e-01, -1.20586958e+00, -3.17414803e+00],\n",
       "       [-1.02145132e+00, -5.37558823e-01, -2.88678035e+00],\n",
       "       [-6.91910476e-01, -9.02358363e-01, -2.36691761e+00],\n",
       "       [-1.49979092e+00, -4.89543927e-01, -1.80839311e+00],\n",
       "       [-5.53626662e-02, -3.18326766e+00, -4.38940911e+00],\n",
       "       [-2.22698609e+00, -5.04345891e+00, -1.21381948e-01],\n",
       "       [-6.55778432e-01, -2.70686017e+00, -8.81367506e-01],\n",
       "       [-4.65174895e-01, -1.32446764e+00, -2.24403092e+00],\n",
       "       [-1.73374006e+00, -2.03954541e-01, -4.84368588e+00],\n",
       "       [-2.23960433e+00, -1.80681788e-01, -2.83364003e+00],\n",
       "       [-9.12589591e-01, -5.33340231e-01, -4.43335128e+00],\n",
       "       [-1.13995658e+00, -1.08096985e+00, -1.07616386e+00],\n",
       "       [-2.89828434e+00, -2.55838771e-01, -1.76834276e+00],\n",
       "       [-2.23479635e+00, -1.83024795e+00, -3.11138665e-01],\n",
       "       [-5.03923328e-02, -3.06248403e+00, -6.04388205e+00],\n",
       "       [-6.44791082e-01, -7.50861207e-01, -5.72360386e+00],\n",
       "       [-7.02601055e+00, -4.41310754e+00, -1.30912512e-02],\n",
       "       [-7.35822855e-02, -3.54154682e+00, -3.17075678e+00],\n",
       "       [-3.30457834e+00, -3.82781296e-02, -7.08200029e+00],\n",
       "       [-2.28283555e+00, -2.09336422e+00, -2.55235935e-01]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['7']\n",
      " ['7']\n",
      " ['7']\n",
      " ['7']\n",
      " ['7']\n",
      " ['7']\n",
      " ['7']\n",
      " ['*7']\n",
      " ['*6']\n",
      " ['6']\n",
      " ['6']\n",
      " ['6']\n",
      " ['6']\n",
      " ['3']\n",
      " ['3']\n",
      " ['*3']\n",
      " ['*3']\n",
      " ['*3']\n",
      " ['*7']\n",
      " ['7']\n",
      " ['7']\n",
      " ['*7']\n",
      " ['*3']\n",
      " ['*3']\n",
      " ['*7']\n",
      " ['*7']\n",
      " ['7']\n",
      " ['7']\n",
      " ['7']\n",
      " ['7']\n",
      " ['7']\n",
      " ['7']\n",
      " ['7']\n",
      " ['7']\n",
      " ['7']]\n",
      "Locations of asterisks: [7, 8, 15, 16, 17, 18, 21, 22, 23, 24, 25]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an empty list to store the rows of the new array\n",
    "new_rows = []\n",
    "asterisk_locations = []\n",
    "\n",
    "# Loop through each row in the original array\n",
    "for i, row in enumerate(prediction_array[:,10,:]):\n",
    "    # Find indices where values are higher than -0.5\n",
    "    indices = np.where(row > -0.5)[0]\n",
    "    \n",
    "    # If there are no values higher than -0.5\n",
    "    if len(indices) == 0:\n",
    "        # Find the index of the maximum value\n",
    "        max_index = np.argmax(row)\n",
    "        # Append a new row with an asterisk and the index of the maximum value\n",
    "        new_row = ['*' + str(3 if max_index == 0 else 6 if max_index == 1 else 7)]\n",
    "        # Add the row index to the asterisk_locations list\n",
    "        asterisk_locations.append(i)\n",
    "    else:\n",
    "        # Replace 0 with 3, 1 with 6, and 2 with 7\n",
    "        indices = [3 if idx == 0 else 6 if idx == 1 else 7 for idx in indices]\n",
    "        # Append a new row with the modified indices\n",
    "        new_row = list(indices)\n",
    "\n",
    "    # Append the new row to the list of rows\n",
    "    new_rows.append(new_row)\n",
    "\n",
    "# Convert the list of rows into a numpy array\n",
    "new_array = np.array(new_rows)\n",
    "\n",
    "# Print the new array\n",
    "print(new_array[:])\n",
    "print(\"Locations of asterisks:\", asterisk_locations)\n",
    "len(asterisk_locations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\gilad\\MI-VR_Project\\Full_Pipeline_15-01.ipynb Cell 38\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/gilad/MI-VR_Project/Full_Pipeline_15-01.ipynb#X52sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39mwhere(new_array[:,\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m7\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'new_array' is not defined"
     ]
    }
   ],
   "source": [
    "print(np.where(new_array[:,0] == '7')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Right' 'Left' 'Left' 'Right' 'Left' 'Left' 'Resting' 'Right' 'Left'\n",
      " 'Left' 'Right' 'Right' 'Resting' 'Resting' 'Resting' 'Resting' 'Resting'\n",
      " 'Right' 'Right' 'Left' 'Left' 'Right' 'Left' 'Resting' 'Left' 'Right'\n",
      " 'Right' 'Right' 'Left' 'Resting' 'Resting' 'Right' 'Left' 'Right'\n",
      " 'Resting' 'Resting' 'Right' 'Right' 'Right' 'Resting' 'Right' 'Right'\n",
      " 'Resting' 'Left' 'Left' 'Left' 'Left' 'Left' 'Right' 'Left' 'Left'\n",
      " 'Right' 'Left' 'Left' 'Right' 'Left' 'Right' 'Right' 'Left' 'Resting']\n"
     ]
    }
   ],
   "source": [
    "prediction=trained_clf.predict(data_to_predict)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Values occur in both arrays: 4\n",
      "2. Values occur only in array no.1: 16\n",
      "3. Values occur only in array no.2: 19\n"
     ]
    }
   ],
   "source": [
    "array1 = np.where(preprocessing_dict['epochs'].events == 3)\n",
    "array2 = np.where(prediction == 'Right')\n",
    "## array2 = np.where(new_array[:,0] == '7')\n",
    "\n",
    "# Values occur in both arrays\n",
    "common_values = np.intersect1d(array1, array2)\n",
    "count_common_values = len(common_values)\n",
    "\n",
    "# Values occur only in array no.1\n",
    "unique_values_array1 = np.setdiff1d(array1, array2)\n",
    "count_unique_values_array1 = len(unique_values_array1)\n",
    "\n",
    "# Values occur only in array no.2\n",
    "unique_values_array2 = np.setdiff1d(array2, array1)\n",
    "count_unique_values_array2 = len(unique_values_array2)\n",
    "\n",
    "print(f\"1. Values occur in both arrays: {count_common_values}\")\n",
    "print(f\"2. Values occur only in array no.1: {count_unique_values_array1}\")\n",
    "print(f\"3. Values occur only in array no.2: {count_unique_values_array2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'column1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[214], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m where_above_threshold_count_1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(\u001b[43mcolumn1\u001b[49m \u001b[38;5;241m>\u001b[39m threshold1)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(where_above_threshold_count_1)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'column1' is not defined"
     ]
    }
   ],
   "source": [
    "where_above_threshold_count_1 = np.where(column1 > threshold1)[0]\n",
    "print(where_above_threshold_count_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare prediction performance by threshold to that of .predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_predict=preprocessing_dict['epochs'].copy().crop(tmin=0.5,tmax=1).get_data()[:,:]\n",
    "thresholded_prediction=trained_clf.decision_function(data_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 24 11\n"
     ]
    }
   ],
   "source": [
    "column0 = thresholded_prediction[:, 0]\n",
    "column1 = thresholded_prediction[:, 1]\n",
    "column2 = thresholded_prediction[:, 2]\n",
    "\n",
    "threshold0 = -0.976948\t\n",
    "threshold1 = -1.096539\n",
    "threshold2 = -0.697421\n",
    "\n",
    "above_threshold_count_0 = (column0 >= threshold0).sum()\n",
    "above_threshold_count_1 = (column1 >= threshold1).sum()\n",
    "above_threshold_count_2 = (column2 >= threshold2).sum()\n",
    "print(above_threshold_count_0,above_threshold_count_1,above_threshold_count_2)\n",
    "\n",
    "where_above_threshold_count_0 = np.where(column0 >= threshold0)[0]\n",
    "where_above_threshold_count_1 = np.where(column1 >= threshold1)[0]\n",
    "where_above_threshold_count_2 = np.where(column2 >= threshold2)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Left', 'Resting', 'Left', 'Resting', 'Left', 'Left', 'Resting',\n",
       "       'Resting', 'Left', 'Right', 'Left', 'Resting', 'Left', 'Right',\n",
       "       'Left', 'Left', 'Right', 'Resting', 'Left', 'Right', 'Right',\n",
       "       'Right', 'Resting', 'Left', 'Left', 'Right', 'Right', 'Right',\n",
       "       'Resting', 'Left', 'Right', 'Right', 'Resting', 'Left', 'Resting',\n",
       "       'Left', 'Resting', 'Right', 'Resting', 'Left', 'Left', 'Resting',\n",
       "       'Right', 'Left', 'Left', 'Resting', 'Right', 'Right', 'Resting',\n",
       "       'Left', 'Right', 'Left', 'Left', 'Left', 'Left', 'Right', 'Right',\n",
       "       'Left', 'Left', 'Left'], dtype='<U7')"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction=trained_clf.predict(data_to_predict)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x150 with 4 Axes>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_preprocessing_dict['epochs']['Right'].pick_channels(['C3','Cz','C4']).compute_psd(fmin=8, fmax=32, tmin=0,tmax=4).plot_topomap(bands = {'Mu (8-13 Hz)': (8, 13), 'Beta (14-28 Hz)': (14, 28)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run on a single participant - with a single recording file (no concatination of files is needed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration on subject: NH_Block_Default.xdf\n",
      "setting up current params: iteration 0 - grid settings: (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n",
      "running a single iteration with the following paramaters: {'LowPass': 7, 'HighPass': 32, 'PerformCsd': True, 'filter_method': 'iir', 'n_components': 4, 'n_components_fbcsp': 4, 'filters_bands': [[8, 12], [12, 20]], 'Electorde_Group': ['C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6', 'CP5', 'CP3', 'CP1', 'CPz', 'CP2', 'CP4', 'CP6', 'TP7', 'TP8', 'PO7', 'PO3', 'POz', 'PO4', 'PO8', 'P7', 'P5', 'P3', 'P1', 'Pz', 'P2', 'P4', 'P6', 'P8'], 'Electorde_Group_name': 'C+CP+PO+P', 'epoch_tmin': -3, 'epoch_tmax': 4, 'classifier_window_s': 1, 'classifier_window_e': 3, 'augmentation_params': {'win_len': 1, 'win_step': 0.1}, 'windowed_prediction_params': {'win_len': 0.5, 'win_step': 0.1}, 'pipeline_name': 'csp+lda', 'subject': 'NH', 'recording_file': 'NH_Block_Default.xdf'}\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "file c:\\Users\\gilad\\MI-VR_Project\\Recordings\\NH_Block_Default.xdf does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mrunning a single iteration with the following paramaters:\u001b[39m\u001b[39m'\u001b[39m,params_dict)\n\u001b[0;32m     32\u001b[0m \u001b[39m#test it: \u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m train_inds,validation_inds,preprocessing_dict\u001b[39m=\u001b[39mrun_pre_processing_extract_validation_set(recording_path,current_path,params_dict)\n\u001b[0;32m     34\u001b[0m params_dict[\u001b[39m'\u001b[39m\u001b[39mpreprocessing_dict\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39mpreprocessing_dict\n\u001b[0;32m     35\u001b[0m fig,w_times,scores_windows,folds_confusion_metrices_per_window,validation_scores,validation_confusion_metrices_per_window,trained_clf\u001b[39m=\u001b[39mrun_training_and_classification_on_selected_params(params_dict,preprocessing_dict,to_plot\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,figure_outputs_path\u001b[39m=\u001b[39mfigure_outputs_path,fig_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[6], line 15\u001b[0m, in \u001b[0;36mrun_pre_processing_extract_validation_set\u001b[1;34m(recording_path, current_path, params_dict)\u001b[0m\n\u001b[0;32m     12\u001b[0m events_trigger_dict\u001b[39m=\u001b[39m{val:key \u001b[39mfor\u001b[39;00m key,val \u001b[39min\u001b[39;00m events_trigger_dict\u001b[39m.\u001b[39mitems()}\n\u001b[0;32m     14\u001b[0m \u001b[39m#read the file:\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m Raw\u001b[39m=\u001b[39mread_raw_xdf(recording_path \u001b[39m/\u001b[39;49m params_dict[\u001b[39m'\u001b[39;49m\u001b[39mrecording_file\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m     16\u001b[0m \u001b[39m#remove non existent channels: \u001b[39;00m\n\u001b[0;32m     17\u001b[0m Raw\u001b[39m.\u001b[39mdrop_channels([\u001b[39m'\u001b[39m\u001b[39mACC_X\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mACC_Y\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mACC_Z\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39m## Drop non eeg channels\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gilad\\MI-VR_Project\\mne_import_xdf.py:166\u001b[0m, in \u001b[0;36mread_raw_xdf\u001b[1;34m(fname, stream_id)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_raw_xdf\u001b[39m(fname, stream_id\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    151\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Read XDF file.\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \n\u001b[0;32m    153\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[39m        XDF file data.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 166\u001b[0m     streams, header \u001b[39m=\u001b[39m load_xdf(fname)\n\u001b[0;32m    168\u001b[0m     \u001b[39mif\u001b[39;00m stream_id \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    169\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(stream_id, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\BCIEnvironment\\lib\\site-packages\\pyxdf\\pyxdf.py:231\u001b[0m, in \u001b[0;36mload_xdf\u001b[1;34m(filename, select_streams, on_chunk, synchronize_clocks, handle_clock_resets, dejitter_timestamps, jitter_break_threshold_seconds, jitter_break_threshold_samples, clock_reset_threshold_seconds, clock_reset_threshold_stds, clock_reset_threshold_offset_seconds, clock_reset_threshold_offset_stds, winsor_threshold, verbose)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[39m# XML content of the file header chunk\u001b[39;00m\n\u001b[0;32m    229\u001b[0m fileheader \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 231\u001b[0m \u001b[39mwith\u001b[39;00m open_xdf(filename) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m    232\u001b[0m     \u001b[39m# for each chunk\u001b[39;00m\n\u001b[0;32m    233\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    234\u001b[0m         \u001b[39m# noinspection PyBroadException\u001b[39;00m\n\u001b[0;32m    235\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    236\u001b[0m             \u001b[39m# read [NumLengthBytes], [Length]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\BCIEnvironment\\lib\\site-packages\\pyxdf\\pyxdf.py:420\u001b[0m, in \u001b[0;36mopen_xdf\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[39m# check absolute path after following symlinks\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m filename\u001b[39m.\u001b[39mresolve()\u001b[39m.\u001b[39mexists():\n\u001b[1;32m--> 420\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mfile \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m does not exist.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m filename)\n\u001b[0;32m    422\u001b[0m \u001b[39mif\u001b[39;00m filename\u001b[39m.\u001b[39msuffix \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.xdfz\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m filename\u001b[39m.\u001b[39msuffixes \u001b[39m==\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39m.xdf\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m.gz\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    423\u001b[0m     f \u001b[39m=\u001b[39m gzip\u001b[39m.\u001b[39mopen(\u001b[39mstr\u001b[39m(filename), \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mException\u001b[0m: file c:\\Users\\gilad\\MI-VR_Project\\Recordings\\NH_Block_Default.xdf does not exist."
     ]
    }
   ],
   "source": [
    "#cell is suitable for the old participants with a single recording file - dont use on roi! \n",
    "#uncomment the \"\"\" to use it: \n",
    "\n",
    "\n",
    "#define which subject to currently check: (here you can also try to define the filename explicitly, if you dont want to work with the \"recording files list that is created earlier\")\n",
    "recording_file=recording_files[6]\n",
    "Subject=subject_names[6]\n",
    "\n",
    "print(f'iteration on subject: {recording_file}')\n",
    "#put all in a single params_dictionary for the current run: \n",
    "\n",
    "#get all possible grid_search combinations: \n",
    "grid_search_dict_copy=grid_search_dict.copy()\n",
    "all_grid_combinations = list(itertools.product(*all_options))\n",
    "iteration_ind=0 #select some grid search combination - you can manualy change the params after getting the \"params_dict\" below\n",
    "\n",
    "#here i can change manually the current iteration params: \n",
    "grid_search_dict_copy['Electorde_Groups_names_grid']=['C+CP+PO+P']\n",
    "grid_search_dict_copy['filters_bands']=[[[8,12],[12,20]]]#[[[8,12], [12, 16],[16,20],[20,24],[24,28],[28,32]]]\n",
    "#this cell allow to test specific iterations\n",
    "params_dict=set_up_params_for_current_grid_iteration(all_grid_combinations,iteration_ind,grid_search_dict_copy)\n",
    "#remember - you can change param_dict manualy - ALL of its keys, so before examining your iteration, make sure that you manually adressed all the relevant keys to change. \n",
    "params_dict['subject']=Subject\n",
    "params_dict['recording_file']=recording_file\n",
    "params_dict['augmentation_params']={'win_len': 1, 'win_step': 0.1}\n",
    "params_dict['classifier_window_s']=1\n",
    "params_dict['classifier_window_e']=3\n",
    "params_dict['pipeline_name']='csp+lda'\n",
    "params_dict['n_components_fbcsp']=4\n",
    "print('running a single iteration with the following paramaters:',params_dict)\n",
    "\n",
    "#test it: \n",
    "train_inds,validation_inds,preprocessing_dict=run_pre_processing_extract_validation_set(recording_path,current_path,params_dict)\n",
    "params_dict['preprocessing_dict']=preprocessing_dict\n",
    "fig,w_times,scores_windows,folds_confusion_metrices_per_window,validation_scores,validation_confusion_metrices_per_window,trained_clf=run_training_and_classification_on_selected_params(params_dict,preprocessing_dict,to_plot=True,figure_outputs_path=figure_outputs_path,fig_name='test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example of how to plot a confusion  matrix from the first fold (training set) on the first window\n",
    "disp=ConfusionMatrixDisplay(folds_confusion_metrices_per_window[1][0],display_labels=trained_clf.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "\n",
    "disp=ConfusionMatrixDisplay(np.array(validation_confusion_metrices_per_window).mean(axis=0),display_labels=trained_clf.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chosen window prediction range is [1, 2]\n",
      "note that the prediction paramaters (that the classifier is trained on) are: {'win_len': 0.5, 'win_step': 0.1}\n",
      "consider if you want the preciction range to match the prediction_param\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 167 is out of bounds for axis 0 with size 60",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\gilad\\MI-VR_Project\\MI_MNI_full_hypter_param_search_with_fbcsp_added_multi_class_graphs_latests - Copy.ipynb Cell 20\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gilad/MI-VR_Project/MI_MNI_full_hypter_param_search_with_fbcsp_added_multi_class_graphs_latests%20-%20Copy.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#plot and extract relevfant decision information for the precision recall curve - this time suited to 2 classes (binary classification) - which basicly means that the output score is single (and not 2 scores are you  might have expected)\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/gilad/MI-VR_Project/MI_MNI_full_hypter_param_search_with_fbcsp_added_multi_class_graphs_latests%20-%20Copy.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m return_df\u001b[39m=\u001b[39mplot_precision_recall_curves_from_trained_classifier(preprocessing_dict,params_dict,precision_recall_curve_timerange\u001b[39m=\u001b[39;49m[\u001b[39m1\u001b[39;49m,\u001b[39m2\u001b[39;49m],trained_clf\u001b[39m=\u001b[39;49mtrained_clf,predict_validation\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gilad/MI-VR_Project/MI_MNI_full_hypter_param_search_with_fbcsp_added_multi_class_graphs_latests%20-%20Copy.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m display(return_df)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gilad/MI-VR_Project/MI_MNI_full_hypter_param_search_with_fbcsp_added_multi_class_graphs_latests%20-%20Copy.ipynb#X25sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m data_to_predict\u001b[39m=\u001b[39mpreprocessing_dict[\u001b[39m'\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mcopy()\u001b[39m.\u001b[39mcrop(tmin\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,tmax\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)\u001b[39m.\u001b[39mget_data()[:,:]\n",
      "\u001b[1;32mc:\\Users\\gilad\\MI-VR_Project\\MI_MNI_full_hypter_param_search_with_fbcsp_added_multi_class_graphs_latests - Copy.ipynb Cell 20\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gilad/MI-VR_Project/MI_MNI_full_hypter_param_search_with_fbcsp_added_multi_class_graphs_latests%20-%20Copy.ipynb#X25sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     inds\u001b[39m=\u001b[39mpreprocessing_dict[\u001b[39m'\u001b[39m\u001b[39mtrain_inds\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gilad/MI-VR_Project/MI_MNI_full_hypter_param_search_with_fbcsp_added_multi_class_graphs_latests%20-%20Copy.ipynb#X25sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m#extract the labels: \u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/gilad/MI-VR_Project/MI_MNI_full_hypter_param_search_with_fbcsp_added_multi_class_graphs_latests%20-%20Copy.ipynb#X25sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m labels\u001b[39m=\u001b[39mpreprocessing_dict[\u001b[39m'\u001b[39;49m\u001b[39mepochs\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mevents[inds, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gilad/MI-VR_Project/MI_MNI_full_hypter_param_search_with_fbcsp_added_multi_class_graphs_latests%20-%20Copy.ipynb#X25sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m#extract the decision function: \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gilad/MI-VR_Project/MI_MNI_full_hypter_param_search_with_fbcsp_added_multi_class_graphs_latests%20-%20Copy.ipynb#X25sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m decision_function\u001b[39m=\u001b[39mtrained_clf\u001b[39m.\u001b[39mdecision_function(preprocessing_dict[\u001b[39m'\u001b[39m\u001b[39mfilter_bank_epochs\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mcopy()\u001b[39m.\u001b[39mcrop(tmin\u001b[39m=\u001b[39mprecision_recall_curve_timerange[\u001b[39m0\u001b[39m],tmax\u001b[39m=\u001b[39mprecision_recall_curve_timerange[\u001b[39m1\u001b[39m])\u001b[39m.\u001b[39mget_data()[inds,:])\n",
      "\u001b[1;31mIndexError\u001b[0m: index 167 is out of bounds for axis 0 with size 60"
     ]
    }
   ],
   "source": [
    "#plot and extract relevfant decision information for the precision recall curve - this time suited to 2 classes (binary classification) - which basicly means that the output score is single (and not 2 scores are you  might have expected)\n",
    "return_df=plot_precision_recall_curves_from_trained_classifier(preprocessing_dict,params_dict,precision_recall_curve_timerange=[1,2],trained_clf=trained_clf,predict_validation=True)\n",
    "display(return_df)\n",
    "\n",
    "data_to_predict=preprocessing_dict['epochs'].copy().crop(tmin=0,tmax=4).get_data()[:,:]\n",
    "thresholded_prediction=trained_clf.decision_function(data_to_predict)<0.520642 #example of how to use a custom threshold you extracted from the return_df\n",
    "prediction=trained_clf.predict(data_to_predict)\n",
    "\n",
    "#show the difference between the custom and the default prediction thresholds.  \n",
    "pd.DataFrame({'thresholded':thresholded_prediction,'default':prediction})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## this section runs custom grid search for neta: \n",
    "### didnt update this code to work with the combined_preprocessing_structure of roi (shouldnt be too much changes needed)\n",
    "#### defines a custom grid \n",
    "#### define the participant name and file \n",
    "#### run the grid search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid options [[0], [0], [0, 1], [0, 1], [0, 1, 2, 3], [0, 1], [0], [0], [0], [0, 1], [0, 1], [0]]\n",
      "number of grid search iterations: 128\n"
     ]
    }
   ],
   "source": [
    "#simple named groups: \n",
    "Electorde_Groups = {'FP': ['Fp1', 'Fp2'],\n",
    "                   'AF': ['AF7', 'AF3', 'AFz', 'AF4', 'AF8'],\n",
    "                   'F' : ['F7', 'F5', 'F3', 'F1', 'Fz', 'F2', 'F4', 'F6', 'F8'],\n",
    "                   'FC': ['FC5', 'FC3', 'FC1', 'FC2', 'FC4', 'FC6', 'FT7','FT8'],\n",
    "                   'C' : ['C5', 'C3', 'C1', 'Cz', 'C2', 'C4' ,'C6'],\n",
    "                   'CP': ['CP5', 'CP3', 'CP1','CPz', 'CP2', 'CP4', 'CP6'],\n",
    "                   'P' : ['P7', 'P5','P3', 'P1', 'Pz', 'P2', 'P4', 'P6', 'P8'],\n",
    "                   'PO': ['PO7', 'PO3', 'POz', 'PO4', 'PO8'],\n",
    "                   'O' : ['Oz', 'O2', 'O1', 'Iz']\n",
    "                  } \n",
    "#set up custom group names: \n",
    "Electorde_Groups = {'Motor_cortex':['F3', 'F1', 'Fz', 'F2', 'F4']+['FC3', 'FC1', 'FC2', 'FC4']+['C3', 'C1', 'Cz', 'C2', 'C4']+\n",
    "                    ['CP3', 'CP1','CPz', 'CP2', 'CP4']+['P3', 'P1', 'Pz', 'P2', 'P4'],\n",
    "                    'Motor_cortex_extended': ['F3', 'F1', 'Fz', 'F2', 'F4']+['FC3', 'FC1', 'FC2', 'FC4']+['C5','C3', 'C1', 'Cz', 'C2', 'C4','C6']+\n",
    "                    ['CP3', 'CP1','CPz', 'CP2', 'CP4']+['P3', 'P1', 'Pz', 'P2', 'P4'],\n",
    "                    'Visual_cortex': ['P7', 'P5','P3', 'P1', 'Pz', 'P2', 'P4', 'P6', 'P8']+['PO7', 'PO3', 'POz', 'PO4', 'PO8']+['Oz', 'O2', 'O1', 'Iz'],\n",
    "                    'all':  ['Fp1', 'Fp2']+['AF7', 'AF3', 'AFz', 'AF4', 'AF8']+ ['F7', 'F5', 'F3', 'F1', 'Fz', 'F2', 'F4', 'F6', 'F8']+\n",
    "                    ['FC5', 'FC3', 'FC1', 'FC2', 'FC4', 'FC6', 'FT7','FT8']+['C5', 'C3', 'C1', 'Cz', 'C2', 'C4' ,'C6']+['CP5', 'CP3', 'CP1','CPz', 'CP2', 'CP4', 'CP6']+\n",
    "                    ['P7', 'P5','P3', 'P1', 'Pz', 'P2', 'P4', 'P6', 'P8']+['PO7', 'PO3', 'POz', 'PO4', 'PO8']+['Oz', 'O2', 'O1', 'Iz'],\n",
    "                    'Motor_cortex_extended_po': ['F3', 'F1', 'Fz', 'F2', 'F4']+['FC3', 'FC1', 'FC2', 'FC4']+['C5','C3', 'C1', 'Cz', 'C2', 'C4','C6']+\n",
    "                    ['CP3', 'CP1','CPz', 'CP2', 'CP4']+['P3', 'P1', 'Pz', 'P2', 'P4']+['PO3', 'POz', 'PO4']}\n",
    "\n",
    "\n",
    "\n",
    "#set the current search: \n",
    "grid_search_dict=OrderedDict()\n",
    "grid_search_dict={'filter_methods':['iir'], #['irr' or 'fir']\n",
    "                'run_csd':[True],\n",
    "                'pipeline_name':['csp+lda','ts+lda'],#'fbcsp+lda'], #these classifiers pipelines are defined in \"run_windowed_classification_on_fold\"\n",
    "                #things to do: filter bank csp + lda, csp+ts+lda\n",
    "                'bandpass_borders_grid':[[7,32],[8,30]], #each list defines the low and high cutoffs\n",
    "                'Electorde_Groups_names_grid':['Motor_cortex','Motor_cortex_extended','Motor_cortex_extended_po','all'], #each \"name\" refers to an elec group defined above\n",
    "                'n_components_grid':[4,6], #the n component options for the csp classifier\n",
    "                'n_components_fbcsp_grid':[2], # the n components options to use in the fbcsp classifier (n * filter_bank_bands)\\\n",
    "                'filters_bands':[[[8, 12], [12, 20], [20, 32]]],\n",
    "                'epoch_tmins_and_maxes_grid':[[-3,4]], #times (sec: pre,post) for initial epoching (this should be the longest epoch as the windowed prediction will be tested on it)\n",
    "                'classifier_training_windows_grid':[[0.5 , 3.5],[1,4]], #what times(sec: start,end) to use for the classifer training (data augmentation is also using this window)\n",
    "                'augmentation_windows_grid':[[1,0.2],[1,0.1]], #referes to proportions (win_len,win_step) of sfreq, [1,1] means taking the classification epochs, and creating 1 second long epochs with 1 second long steps\n",
    "                'windowed_prediction_params':[[1,0.1]]} #refers to prportions (win_len,win_step) of sfreq to try and predict i.e. 0.5 = half a second window, with a 100ms steps  \n",
    "\n",
    "all_options=[list(range(len(val))) for key,val in grid_search_dict.items()]\n",
    "print(f'grid options {all_options}')\n",
    "#get all possible grid_search combinations: \n",
    "all_grid_combinations = list(itertools.product(*all_options))\n",
    "print(f'number of grid search iterations: {len(all_grid_combinations)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run a grid search on a single participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subject_name='Neta'\n",
    "recording_file_name='Neta_NoAO_1Hand.xdf'\n",
    "grid_search_data_frame_info=run_grid_search_on_single_participant(grid_search_dict,recording_file_name,Subject_name,save_every_n_iter=5,save_location_path=hyper_param_search_output,to_plot=False)\n",
    "display(grid_search_data_frame_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_data_frame_info"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run the entire grid search (on all participants): save the outcomes in a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for recording_file,Subject in tqdm(zip(recording_files,subject_names)): #run on all participants: \n",
    "    Subject_name=Subject\n",
    "    recording_file_name=recording_file\n",
    "    grid_search_data_frame_info=run_grid_search_on_single_participant(grid_search_dict,recording_file_name,Subject_name,save_every_n_iter=5,save_location_path=hyper_param_search_output,to_plot=True)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## take all the rest of the code from here: \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the cells below load up the grid search to look for the best hyper paramaters: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WindowsPath('c:/Users/d_abe/Desktop/mental imagery project/MI-VR_Project/hyper_param_search_outputs/best_hyper_params_max_prediction.csv'), WindowsPath('c:/Users/d_abe/Desktop/mental imagery project/MI-VR_Project/hyper_param_search_outputs/best_hyper_params_mean_prediction.csv'), WindowsPath('c:/Users/d_abe/Desktop/mental imagery project/MI-VR_Project/hyper_param_search_outputs/hypter_param_search_Dekel_AO.csv'), WindowsPath('c:/Users/d_abe/Desktop/mental imagery project/MI-VR_Project/hyper_param_search_outputs/hypter_param_search_Dekel_AoNoMI.csv'), WindowsPath('c:/Users/d_abe/Desktop/mental imagery project/MI-VR_Project/hyper_param_search_outputs/hypter_param_search_Dekel_NoAO.csv'), WindowsPath('c:/Users/d_abe/Desktop/mental imagery project/MI-VR_Project/hyper_param_search_outputs/hypter_param_search_Gilad_AO.csv'), WindowsPath('c:/Users/d_abe/Desktop/mental imagery project/MI-VR_Project/hyper_param_search_outputs/hypter_param_search_Neta_AO_1Hand.csv'), WindowsPath('c:/Users/d_abe/Desktop/mental imagery project/MI-VR_Project/hyper_param_search_outputs/hypter_param_search_Neta_AO_2Hands.csv'), WindowsPath('c:/Users/d_abe/Desktop/mental imagery project/MI-VR_Project/hyper_param_search_outputs/hypter_param_search_Neta_NoAO_1Hand.csv'), WindowsPath('c:/Users/d_abe/Desktop/mental imagery project/MI-VR_Project/hyper_param_search_outputs/hypter_param_search_Neta_NoAO_2Hands.csv')]\n"
     ]
    }
   ],
   "source": [
    "subject_specific_hyper_param_csvs=[curr_csv for curr_csv in hyper_param_search_output.iterdir() if (('.csv' in curr_csv.name))]\n",
    "print(subject_specific_hyper_param_csvs)\n",
    "\n",
    "#read the saved dataframes: also note that when cells with np array were saved, they are read out as strings so we need to convert them back to np arrays for easy of use\n",
    "def convert_saved_string_to_np_array(string):\n",
    "    array_format=np.array([float(num) for num in string.replace('[','').replace(']','').replace('\\n','').split(' ') if len(num)>0])\n",
    "    return array_format\n",
    "#this section loads and concatinate all hyper params searchs into a single df\n",
    "subjects_df_all=pd.concat([pd.read_csv(curr_csv,index_col=0,dtype={ 'mean_scores':object,\n",
    "       'std_scores':object, 'w_times':object,'validation_scores':object},converters={ 'mean_scores':convert_saved_string_to_np_array,\n",
    "       'std_scores':convert_saved_string_to_np_array, 'w_times':convert_saved_string_to_np_array,'validation_scores':convert_saved_string_to_np_array}) for curr_csv in subject_specific_hyper_param_csvs],axis=0)\n",
    "subjects_df_all.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this section create functions used to infer the w_times vector (the time stamp of the middle of a prediction window) based on the\n",
    "#prediction paramaters in the dataframe\n",
    "\n",
    "def isfloat(num):\n",
    "    try:\n",
    "        float(num)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "def calculate_w_times(row):\n",
    "        min_time = row['epoch_tmin']\n",
    "        max_time = row['epoch_tmax']\n",
    "        pred_win_string = row['windowed_prediction_params'].replace('{','').replace('}','').replace(',','')\n",
    "        pred_win_len = [float(x) for x in pred_win_string.split(':')[1].split(' ') if isfloat(x)][0]\n",
    "        pred_win_step = [float(x) for x in pred_win_string.split(':')[2].split(' ') if isfloat(x)][0]\n",
    "        first_window = min_time \n",
    "        last_window = max_time - pred_win_len \n",
    "        w_times = np.linspace(first_window,last_window,row['mean_scores'].shape[0])\n",
    "        assert(row['mean_scores'].shape==w_times.shape)\n",
    "        return w_times\n",
    "\n",
    "#this is where we define a function to search for the best performence over a requested window (prediction window defined by the timestamp of its start)\n",
    "def get_performence_in_time_window(subjects_df_all,time_window,operation='mean'):\n",
    "    #time window defineds the time stamp of the start of the window\n",
    "    #possible operations: \"mean\",'max','min'\n",
    "    \n",
    "    values=subjects_df_all['mean_scores'].values\n",
    "    times=subjects_df_all['w_times'].values\n",
    "    extracted_values=[]\n",
    "    for curr_times,curr_values in zip(times,values): \n",
    "        rel_values=curr_values[(curr_times>time_window[0]) & (curr_times<=time_window[1])]\n",
    "        if operation=='mean':\n",
    "            val=np.mean(rel_values)\n",
    "        elif operation=='max':\n",
    "            val=np.max(rel_values)\n",
    "        elif operation=='min':\n",
    "            val=np.min(rel_values)    \n",
    "        extracted_values.append(val)\n",
    "    return extracted_values\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      max_1_4         mean_1_4       \n",
      "                          max idxmax       max idxmax\n",
      "recording_file                                       \n",
      "Dekel_AO.xdf          0.68750      0  0.653750      8\n",
      "Dekel_AoNoMI.xdf      0.68750      1  0.585000      9\n",
      "Dekel_NoAO.xdf        0.74375      2  0.685312      2\n",
      "Gilad_AO.xdf          0.88750      3  0.789687     11\n",
      "Neta_AO_1Hand.xdf     0.68750      4  0.597187     12\n",
      "Neta_AO_2Hands.xdf    0.76875      5  0.669063     13\n",
      "Neta_NoAO_1Hand.xdf   0.71250      6  0.572283     14\n",
      "Neta_NoAO_2Hands.xdf  0.66250      7  0.536875     15\n"
     ]
    }
   ],
   "source": [
    "#infer w_times\n",
    "subjects_df_all['w_times'] = subjects_df_all.apply(calculate_w_times, axis=1)\n",
    "time_window=[1,4]\n",
    "max_col_name='max'+'_'+str(time_window[0])+'_'+str(time_window[1])\n",
    "mean_col_name='mean'+'_'+str(time_window[0])+'_'+str(time_window[1])\n",
    "subjects_df_all[max_col_name]= get_performence_in_time_window(subjects_df_all,time_window,operation='max') \n",
    "subjects_df_all[mean_col_name]= get_performence_in_time_window(subjects_df_all,time_window,operation='mean') \n",
    "grouped_df=subjects_df_all.groupby(['recording_file']).aggregate({max_col_name:['max','idxmax'],mean_col_name:['max','idxmax']})\n",
    "print(grouped_df)\n",
    "#best hyperparams per subject: \n",
    "best_hyper_params_df_mean_prediction=subjects_df_all.iloc[grouped_df[(mean_col_name,'idxmax')].values]\n",
    "best_hyper_params_df_mean_prediction.to_csv(hyper_param_search_output/'best_hyper_params_mean_prediction.csv',index=False)\n",
    "best_hyper_params_df_max_prediction=subjects_df_all.iloc[grouped_df[(max_col_name,'idxmax')].values]\n",
    "best_hyper_params_df_max_prediction.to_csv(hyper_param_search_output/'best_hyper_params_max_prediction.csv',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to take the \"best_hyper_params_df_max_prediction\" and the required index to plot the results\n",
    "def plot_prediction_time_course_from_hyper_param_search(hyper_param_seach_df,ind):\n",
    "    plot_df=pd.DataFrame({'w_times':hyper_param_seach_df.loc[ind]['w_times'],\n",
    "                        'mean_scores':hyper_param_seach_df.loc[ind]['mean_scores'],\n",
    "                        'std_scores':hyper_param_seach_df.loc[ind]['std_scores'],\n",
    "                        'validation_scores':hyper_param_seach_df.loc[ind]['validation_scores']})\n",
    "    fig=plt.figure()\n",
    "    plt.fill_between(plot_df['w_times'],plot_df['mean_scores']+plot_df['std_scores'],plot_df['mean_scores']-plot_df['std_scores'],alpha=0.25,label=' +-1 std')\n",
    "    sns.lineplot(data=plot_df,x='w_times',y='mean_scores',label='mean cv score',color='g')\n",
    "    sns.lineplot(data=plot_df,x='w_times',y='validation_scores',color='r',label='validation set score')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.grid()\n",
    "    plt.axhline(y=0.5, color='k', linestyle='--')\n",
    "    plt.axvline(x=0,color='k', linestyle='-.')\n",
    "\n",
    "    #get info for title: \n",
    "    filename=hyper_param_seach_df.loc[ind]['recording_file']\n",
    "    max_col_name=[col for col in hyper_param_seach_df.columns if 'max_' in col]\n",
    "    mean_col_name=[col for col in hyper_param_seach_df.columns if (('mean_' in col) and ('scores' not in col))]\n",
    "\n",
    "    max_value=hyper_param_seach_df.loc[ind][max_col_name].values\n",
    "    mean_value=hyper_param_seach_df.loc[ind][mean_col_name].values\n",
    "    prediction_win_params=hyper_param_seach_df.loc[ind]['windowed_prediction_params']\n",
    "    pred_win_string = prediction_win_params.replace('{','').replace('}','').replace(',','')\n",
    "    pred_win_len = [float(x) for x in pred_win_string.split(':')[1].split(' ') if isfloat(x)][0]\n",
    "    pred_win_step = [float(x) for x in pred_win_string.split(':')[2].split(' ') if isfloat(x)][0]\n",
    "\n",
    "    title=f'{filename}\\nwin_size = {pred_win_len}, step_size={pred_win_step}\\ncv scores:\\n{max_col_name}={max_value},{mean_col_name}={mean_value}'\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing it (using the(3rd row - gilad AO, as it looks awesome! :P)) \n",
    "plot_prediction_time_course_from_hyper_param_search(best_hyper_params_df_mean_prediction,best_hyper_params_df_mean_prediction.index[3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mental_Imagery",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8dd1d82d0489786582d665b69714801e3e965ab3972c8c510c769fb6057b2a16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
